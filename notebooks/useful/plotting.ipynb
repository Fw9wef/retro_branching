{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from retro_branching.utils import plot_val_line, get_most_recent_checkpoint_foldername, sns_plot_val_line, gen_co_name\n",
    "\n",
    "import torch\n",
    "torch.cuda.device(1)\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "from sqlitedict import SqliteDict\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Agent Learning Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "learner = 'dqn_learner' # 'reinforce_learner' 'dqn_learner' 'ppo_learner'\n",
    "base_name = 'dqn_gnn' # 'rl_gnn' 'dqn_gnn' 'ppo'\n",
    "\n",
    "# learner = 'ppo_learner' # 'reinforce_learner' 'dqn_learner' 'ppo_learner'\n",
    "# base_name = 'ppo' # 'rl_gnn' 'dqn_gnn' 'ppo'\n",
    "\n",
    "\n",
    "PLOT_BASELINES = False # True False\n",
    "episodes_logs_dict, epochs_logs_dict = {}, {}\n",
    "\n",
    "load_episodes_log = True\n",
    "\n",
    "load_epochs_log = True\n",
    "# load_epochs_log = False\n",
    "\n",
    "\n",
    "\n",
    "########################### RL IDs ##########################\n",
    "\n",
    "# ids = [639, 641] # small, observation_function='label_solution_values'\n",
    "\n",
    "# ids = [643, 644] # large, starting from score imitation policy (trained w/ KLDiv loss function)\n",
    "\n",
    "# ids = [650, 651, 652] # overfitting to a large instance to try beat strong branching (which had 9 nodes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ########################### DQN IDs ###########################\n",
    "\n",
    "\n",
    "# # ids = [1298, 1301] # 100x100 diff n\n",
    "\n",
    "# ids = [1236, 1293, 1299, 1300, 1307, 1308] # 500x1000 diff retro_trajectory_construction reward=-1/0\n",
    "# # ids = [1299, 1300, 1307, 1308]\n",
    "# # ids = [1307, 1308] # max_lp_leaf_gain construction, ablating M-DQN\n",
    "\n",
    "# # ids = [1319, 1316, 1317, 1318] # 100x100 noveld\n",
    "# # ids = [1316, 1317, 1318]\n",
    "# # ids = [1319, 1316, 1317, 1318]\n",
    "# # ids = [1316, 1318]\n",
    "# # ids = [1317, 1318]\n",
    "# # ids = [1318, 1319]\n",
    "\n",
    "# ids = [1236, 1308, 1320, 1359] # 500x1000 NovelD and Tom's hparams\n",
    "# ids = [1308, 1320, 1347, 1348, 1359]\n",
    "# # ids = [1326, 1347, 1359]\n",
    "# # ids = [1347, 1359]\n",
    "# # ids = [1359]\n",
    "\n",
    "# # ids = [1321, 1323, 1322, 1324, 1325] # 100x100 NovelD hparams\n",
    "# # ids = [1321, 1323, 1322] # intrinsic_reward_scaling\n",
    "# # ids = [1321, 1324, 1325] # novelty_difference_scasling\n",
    "\n",
    "# # ids = [1325, 1341, 1342] # 100x100 NovelD with multiple heads\n",
    "# # ids = [1341, 1342]\n",
    "\n",
    "# # ids = [1325, 1355, 1357, 1358] # backtrack rollout expert\n",
    "# # ids = [1355, 1357, 1358]\n",
    "# # ids = [1325, 1357]\n",
    "# # ids = [1357]\n",
    "# # ids = [1236, 1381]\n",
    "# # ids = [1359, 1381]\n",
    "# ids = [1381]\n",
    "\n",
    "# # ids = [1360, 1373, 1374, 1375] # combinatorial auction, diff sizes\n",
    "# # ids = [1373]\n",
    "# # ids = [1374]\n",
    "# ids = [1375]\n",
    "# ids = [1379, 1388]\n",
    "\n",
    "# ids = [1376, 1377] # 100x100 Tom's hparams\n",
    "\n",
    "# # ids = [1373, 1378, 1379, 1380] # CA diff hparams\n",
    "# # ids = [1379, 1380]\n",
    "# ids = [1373, 1378, 1379] # CA diff hparams\n",
    "\n",
    "# ids = [1382] # CFL\n",
    "\n",
    "# ids = [1383, 1390] # MIS\n",
    "\n",
    "# ids = [1376, 1392, 1393] # reward=retro_branching_mcts_backprop\n",
    "\n",
    "# ids = [1376, 1394, 1395] # 100x100 subtrees w/ use_mean_return_rooted_at_node\n",
    "# ids = [1236, 1308, 1396] # 500x1000 subtrees w/ use_mean_return_rooted_at_node\n",
    "# ids = [1308, 1396]\n",
    "# ids = [1396]\n",
    "\n",
    "# ids = [1376, 1397] # 100x100 ablating sub-trees\n",
    "# ids = [1397]\n",
    "# ids = [1236, 1405] # 500x1000 ablating sub-trees\n",
    "# ids = [1405]\n",
    "# ids = [1236, 1401] # 500x1000 ablating M-DQN\n",
    "\n",
    "# ids = [1407] # 165x230\n",
    "\n",
    "# ids = [1376, 1409] # 100x100 fixed optimal path approach\n",
    "\n",
    "# ids = [1376, 1410, 1411, 1412, 1414, 1415, 1424] # 100x100 new use_sum_return_rooted_at_node idea\n",
    "# ids = [1376, 1410, 1411, 1412]\n",
    "# ids = [1410, 1411, 1412, 1414]\n",
    "# ids = [1376, 1412, 1414]\n",
    "# ids = [1412, 1414]\n",
    "# ids = [1415, 1421, 1424]\n",
    "# ids = [1415, 1424]\n",
    "# ids = [1376, 1415]\n",
    "# ids = [1415, 1418, 1414, 1416, 1376, 1424] # sub-tree construction stuides for paper\n",
    "    \n",
    "    \n",
    "\n",
    "# ids = [1415, 1416, 1418] # retro_trajectory_construction=reverse_visitation_order\n",
    "\n",
    "# ids = [1376, 1415] # 100x100 ablating (old 'incorrect') optimal sub-tree\n",
    "\n",
    "# ids = [1236, 1419] # 500x1000 force_include_optimal_trajectory=False\n",
    "# ids = [1419]\n",
    "\n",
    "# ids = [1415, 1422, 1423, 1431] # ablating n-step DQN and M-DQN\n",
    "\n",
    "# ids = [1415, 1425] # 100x100 only_use_leaves_closed_by_brancher_as_terminal_nodes=True\n",
    "\n",
    "# ids = [1412, 1425, 1429, 1428, 1430] # 100x100 trying set_score_as_subtree_size\n",
    "# ids = [1429, 1428, 1430]\n",
    "# ids = [1415]\n",
    "\n",
    "# ids = [1415, 1425, 1432] # 100x100 re-trying subtrees w/ normalised_lp_gain\n",
    "# ids = [1425, 1432]\n",
    "# ids = [1415, 1432]\n",
    "\n",
    "# ids = [1236, 1434, 1435] # 500x1000 re-trying subtrees w/ normalised_lp_gain\n",
    "# ids = [1236, 1435]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ids = [1426, 1436] # 250x500 testing only_use_leaves_closed_by_brancher_as_terminal_nodes\n",
    "\n",
    "# ids = [1436, 1437, 1438, 1439] # 250x500 n-step M-DQN RL algorithm ablation study\n",
    "\n",
    "# ids = [1436, 1440] # 250x500 sub-tree vs. whole tree\n",
    "\n",
    "# ids = [1426, 1436, 1441, 1442, 1443] # 250x500 sub-tree construction test\n",
    "\n",
    "\n",
    "# ids = [1446] # 1000x1000\n",
    "\n",
    "\n",
    "# ids = [1451, 1452, 1453, 1454, 1455, 1456, 1457] # 250x500 sub-tree construction test\n",
    "\n",
    "# ids = [1247, 1448, 1450] # 1000x1000\n",
    "# ids = [1448, 1450]\n",
    "# ids = [1458]\n",
    "\n",
    "# ids = [1440, 1451, 1460] # 250x500 reward=binary_fathomed\n",
    "\n",
    "# ids = [1405, 1236, 1464] # 500x1000 reward=binary_fathomed\n",
    "# ids = [1236, 1464]\n",
    "\n",
    "# ids = [1094, 1470, 1469] # 100x100 subtrees vs. sub-tree sum reward of Etheve et al.\n",
    "# ids = [1236, 1471, 1472] # 500x1000 subtrees vs. sub-tree sum reward of Etheve et al.\n",
    "# ids = [1094, 1430]\n",
    "# ids = [1430, 1470, 1469]\n",
    "\n",
    "ids = [1484, 1481, 1479] # etheve vs. retrospective vs. original\n",
    "ids = [1481, 1485] # step-retro vs. mab-retro\n",
    "\n",
    "# ids = [1481, 1488, 1489, 1490] # subtree construction methods\n",
    "ids = [1481]\n",
    "\n",
    "\n",
    "########################### PPO IDs ###########################\n",
    "# ids = [3, 4, 5]\n",
    "# ids = [5]\n",
    "# ids = [8]\n",
    "# ids = [9, 10]\n",
    "# ids = [11]\n",
    "# ids = [14, 16]\n",
    "# ids = [17]\n",
    "# ids = [20]\n",
    "# ids = [21, 22, 23, 24]\n",
    "# ids = [29]\n",
    "# ids = [30]\n",
    "# ids = [33] # works!\n",
    "# ids = [34, 35, 36]\n",
    "# ids = [34]\n",
    "\n",
    "# ids = [34, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55] # ppo hparam tuning\n",
    "# ids = [34, 39] # value_function_coeff\n",
    "# ids = [34, 40, 41] # eps_clip\n",
    "# ids = [34, 42, 43] # entropy_coeff\n",
    "# ids = [34, 44] # gamma\n",
    "# ids = [34, 45, 46] # ppo_update_freq\n",
    "# ids = [34, 47] # obs\n",
    "# ids = [34, 48] # batch_size\n",
    "# ids = [34, 49] # lr\n",
    "# ids = [34, 50] # ppo_epochs_per_update\n",
    "# ids = [34, 51] # whiten_rewards\n",
    "# ids = [34, 54, 55] # gradient clipping\n",
    "# ids = [54, 55]\n",
    "\n",
    "# ids = [59, 60, 61]\n",
    "\n",
    "# ids = [34, 63, 64, 65, 67, 68] # reward=retro_branching_mcts_backprop\n",
    "# ids = [34, 64, 65]\n",
    "# ids = [64, 65]\n",
    "# ids = [64]\n",
    "# ids = [34, 65, 67, 68]\n",
    "# ids = [67, 68]\n",
    "\n",
    "# ids = [34, 69] # 100x100 subtrees w/ use_mean_return_rooted_at_node\n",
    "# ids = [59, 71, 72] # 500x1000 subtrees w/ use_mean_return_rooted_at_node\n",
    "\n",
    "# ids = [73, 74] # binary fathomed whole tree vs. binary fathomed sub-trees comparison\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in ids:\n",
    "    agent = '{}_{}'.format(base_name, i)\n",
    "    agent_path = '/scratch/datasets/retro_branching/{}/{}/{}/'.format(learner, base_name, agent)\n",
    "    \n",
    "    if os.path.exists(agent_path+'/database'):\n",
    "        # logs saved to sqlite databases\n",
    "        folder = get_most_recent_checkpoint_foldername(agent_path, idx=-1)\n",
    "        print(agent_path+'database', get_most_recent_checkpoint_foldername(agent_path, idx=-1))\n",
    "        \n",
    "        if load_episodes_log:\n",
    "            episodes_logs_dict[agent] = {}\n",
    "            while True:\n",
    "                try:\n",
    "                    with SqliteDict(agent_path+'/database/episodes_log.sqlite') as log:\n",
    "                        for key, val in log.items():\n",
    "                            # read into memory\n",
    "                            episodes_logs_dict[agent][key] = val\n",
    "                        log.close()\n",
    "                    break\n",
    "                except:\n",
    "                    # database locked since is being written to, wait and try again\n",
    "                    time.sleep(1)\n",
    "                \n",
    "        if load_epochs_log:\n",
    "            epochs_logs_dict[agent] = {}\n",
    "            while True:\n",
    "                try:\n",
    "                    with SqliteDict(agent_path+'/database/epochs_log.sqlite') as log:\n",
    "                        for key, val in log.items():\n",
    "                            # read into memory\n",
    "                            epochs_logs_dict[agent][key] = val\n",
    "                        log.close()\n",
    "                        break\n",
    "                except:\n",
    "                    # database locked since is being written to, wait and try again\n",
    "                    time.sleep(1)\n",
    "        if 'episode_run_time' in episodes_logs_dict[agent]:\n",
    "            print('Mean episode run time: {} s'.format(round(np.mean(episodes_logs_dict[agent]['episode_run_time']), 3)))\n",
    "    else:\n",
    "        # logs saved to individual checkpoint folders\n",
    "        foldername = get_most_recent_checkpoint_foldername(agent_path, idx=-2)\n",
    "    #     foldername='checkpoint_4700'\n",
    "        path = '{}{}/'.format(agent_path, foldername)\n",
    "        print(path)\n",
    "        \n",
    "        if load_episodes_log:\n",
    "            if os.path.exists(path+'episodes_log.pkl'):\n",
    "                _f = 'episodes_log.pkl'\n",
    "            else:\n",
    "                _f = '*log.pkl'\n",
    "            with gzip.open(*glob.glob(path+_f), 'rb') as f:\n",
    "                log = pickle.load(f)\n",
    "            episodes_logs_dict[agent] = log\n",
    "            if 'episode_run_time' in log:\n",
    "                print('Mean episode run time: {} s'.format(round(np.mean(log['episode_run_time']), 3)))\n",
    "            else:\n",
    "                # mistakenly called episodes epochs\n",
    "                print('Mean episode run time: {} s'.format(round(np.mean(log['epoch_run_time']), 3)))\n",
    "\n",
    "        if load_epochs_log:\n",
    "            try:\n",
    "                with gzip.open(*glob.glob(path+'epochs_log.pkl'), 'rb') as f:\n",
    "                    log = pickle.load(f)\n",
    "            except FileNotFoundError:\n",
    "                print(f'No epochs_log recorded for agent {agent}')\n",
    "            epochs_logs_dict[agent] = log\n",
    "print('All agent data loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode metrics\n",
    "%autoreload\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "\n",
    "plot_dicts = {}\n",
    "plot_raw_data = False # True False\n",
    "ylogscale = False # True False\n",
    "\n",
    "metrics_to_skip_plotting = {'agent_name', 'agent_reward', 'agent_device', 'batch_size', 'lr', 'gamma', 'threshold_difficulty', 'learner_name', 'episode_counter', 'epoch_counter', 'solving_time', 'primal_integral', 'dual_integral', 'primal_dual_integral', 'episode_run_time', 'dual_bound_frac', 'primal_bound_frac'}\n",
    "\n",
    "# metrics = ['R', 'num_nodes', 'solving_time', 'lp_iterations', 'primal_integral', 'dual_integral', 'primal_dual_integral']\n",
    "# metrics = ['num_nodes', 'lp_iterations', 'num_steps', 'R', 'mean_reward', 'epsilon']\n",
    "# metrics = ['num_nodes']\n",
    "metrics = ['elapsed_training_time']\n",
    "# metrics = [m for m in list(episodes_logs_dict.values())[0].keys() if m not in metrics_to_skip_plotting]\n",
    "\n",
    "# for log_idx in range(len(list(episodes_logs_dict.values()))):\n",
    "#     for idx in range(len(_metrics)):\n",
    "#         print(_metrics[idx])\n",
    "#         print(type(list(episodes_logs_dict.values())[0][_metrics[idx]]))\n",
    "#         print(list(episodes_logs_dict.values())[0][_metrics[idx]][0])\n",
    "#         if type(list(episodes_logs_dict.values())[0][_metrics[idx]][0]) == dict:\n",
    "#             for key in list(episodes_logs_dict.values())[0][_metrics[idx]][0]:\n",
    "#                 metrics.append(key)\n",
    "#             metrics_to_skip_plotting.add(_metrics[idx])\n",
    "# metrics.append('mean_reward')\n",
    "\n",
    "print(metrics)\n",
    "max_idx = 5e6 # 5e6\n",
    "extra_metrics_to_plot = defaultdict(lambda: nested_dict()) # for storing extra metrics calculated below while looping through standard metrics\n",
    "for metric in metrics:\n",
    "    if metric not in metrics_to_skip_plotting:\n",
    "        plot_dict = nested_dict()\n",
    "        for agent, log in episodes_logs_dict.items():\n",
    "            plot_metric_for_agent = True\n",
    "#             print(log.keys())\n",
    "            if metric in log:\n",
    "                if len(log[metric]) != 0:\n",
    "                    if type(log[metric][0]) == dict:\n",
    "                        # returns broken down into reward sub-components and stored in dict, extract sub-components and calc mean\n",
    "        #                 metrics_to_skip_plotting.add(metric)\n",
    "                        plot_metric_for_agent = False\n",
    "                        for reward_name in log[metric][0].keys():\n",
    "                            # return\n",
    "                            x_vals = np.array([log[metric][idx][reward_name] for idx in range(len(log[metric]))])\n",
    "                            extra_metrics_to_plot[f'R_{reward_name}'][agent]['y_values'] = x_vals[:min(len(x_vals), int(max_idx))]\n",
    "                            extra_metrics_to_plot[f'R_{reward_name}'][agent]['x_values'] = range(len(x_vals[:min(len(x_vals), int(max_idx))]))\n",
    "\n",
    "                            # mean\n",
    "                            x_vals = np.array([log[metric][idx][reward_name]/log['num_steps'][idx] for idx in range(len(log[metric]))])\n",
    "                            extra_metrics_to_plot[f'mean_{reward_name}_reward'][agent]['y_values'] = x_vals[:min(len(x_vals), int(max_idx))]\n",
    "                            extra_metrics_to_plot[f'mean_{reward_name}_reward'][agent]['x_values'] = range(len(x_vals[:min(len(x_vals), int(max_idx))]))\n",
    "                else:\n",
    "                    if metric == 'R' and len(log['num_steps']) != 0:\n",
    "                        # use to calc mean reward\n",
    "                        x_vals = np.array([log[metric][idx]/log['num_steps'][idx] for idx in range(len(log[metric]))])\n",
    "                        extra_metrics_to_plot[f'mean_reward'][agent]['y_values'] = x_vals[:min(len(x_vals), int(max_idx))]\n",
    "                        extra_metrics_to_plot[f'mean_reward'][agent]['x_values'] = range(len(x_vals[:min(len(x_vals), int(max_idx))]))\n",
    "\n",
    "                if metric in log.keys() and plot_metric_for_agent:\n",
    "                    plot_dict[agent]['y_values'] = log[metric][:min(len(log[metric]), int(max_idx))]\n",
    "                    plot_dict[agent]['x_values'] = list(range(len(log[metric])))[:min(len(log[metric]), int(max_idx))]\n",
    "#                     plot_dict[agent]['x_values'] = log['num_episodes'][:min(len(log[metric]), int(max_idx))]\n",
    "                else:\n",
    "                    print(f'{metric} not tracked for agent {agent} or plt_metric_for_agent is False')\n",
    "            else:\n",
    "                print(f'Metric {metric} not recorded for agent {agent}')\n",
    "\n",
    "    #     # TEMPORARY\n",
    "    #     if metric == 'num_nodes':\n",
    "    #         horizontal_lines = {'strong_branching': 9}\n",
    "        if metric in ['epsilon']:\n",
    "            moving_average_window = 1\n",
    "        else:\n",
    "            moving_average_window = 100\n",
    "        if plot_raw_data:\n",
    "            _ = sns_plot_val_line(plot_dict,\n",
    "                                  moving_average_window=moving_average_window, # 7 60 200 800\n",
    "                                  plot_unfiltered_data=True, # True\n",
    "        #                           horizontal_lines=horizontal_lines,\n",
    "                                  unfiltered_data_alpha=0.3,\n",
    "                                  xlabel='Episode',\n",
    "                                  ylabel=metric,\n",
    "                                  ylogscale=ylogscale,\n",
    "                                  show_fig=True)\n",
    "        moving_average_window = int(500)\n",
    "        _ = sns_plot_val_line(plot_dict,\n",
    "        #                           horizontal_lines=horizontal_lines,\n",
    "                                  moving_average_window=moving_average_window, # 10 20 500\n",
    "                                  plot_unfiltered_data=False,\n",
    "                                  xlabel='Episode',\n",
    "                                  ylabel=metric,\n",
    "                                  ylogscale=ylogscale,\n",
    "                                  show_fig=True)\n",
    "\n",
    "        plot_dicts[metric] = plot_dict\n",
    "        \n",
    "        \n",
    "# plot any extra metrics\n",
    "for metric, plot_dict in extra_metrics_to_plot.items():\n",
    "    print(metric)\n",
    "    print(plot_dict.keys())\n",
    "    if plot_raw_data:\n",
    "        _ = sns_plot_val_line(plot_dict,\n",
    "                              moving_average_window=100, # 7 60 200 800\n",
    "                              plot_unfiltered_data=True, # True\n",
    "                              unfiltered_data_alpha=0.3,\n",
    "                              xlabel='Episode',\n",
    "                              ylabel=metric,\n",
    "                              ylogscale=ylogscale,\n",
    "                              show_fig=True)\n",
    "\n",
    "    _ = sns_plot_val_line(plot_dict,\n",
    "                          moving_average_window=moving_average_window, # 10 20 500\n",
    "                          plot_unfiltered_data=False,\n",
    "                          xlabel='Episode',\n",
    "                          ylabel=metric,\n",
    "                          ylogscale=ylogscale,\n",
    "                          show_fig=True)\n",
    "\n",
    "    plot_dicts[metric] = plot_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO\n",
    "if learner != 'ppo_learner':\n",
    "    raise Exception('Use this cell for PPO learner.')\n",
    "\n",
    "# epoch metrics\n",
    "%autoreload\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "\n",
    "plot_dicts = {}\n",
    "plot_raw_data = False # True False\n",
    "ylogscale = False # True False\n",
    "\n",
    "metrics_to_skip_plotting = {'agent_name', 'agent_reward', 'agent_device', 'batch_size', 'lr', 'gamma', 'threshold_difficulty', 'learner_name', 'episode_counter', 'epoch_counter', 'solving_time', 'primal_integral', 'dual_integral', 'primal_dual_integral', 'episode_run_time', 'dual_bound_frac', 'primal_bound_frac'}\n",
    "\n",
    "# metrics = ['R', 'num_nodes', 'solving_time', 'lp_iterations', 'primal_integral', 'dual_integral', 'primal_dual_integral']\n",
    "# metrics = ['num_nodes', 'lp_iterations', 'num_steps', 'R', 'mean_reward', 'epsilon']\n",
    "# metrics = ['num_nodes']\n",
    "metrics = [m for m in list(epochs_logs_dict.values())[0].keys() if m not in metrics_to_skip_plotting]\n",
    "\n",
    "# for log_idx in range(len(list(episodes_logs_dict.values()))):\n",
    "#     for idx in range(len(_metrics)):\n",
    "#         print(_metrics[idx])\n",
    "#         print(type(list(episodes_logs_dict.values())[0][_metrics[idx]]))\n",
    "#         print(list(episodes_logs_dict.values())[0][_metrics[idx]][0])\n",
    "#         if type(list(episodes_logs_dict.values())[0][_metrics[idx]][0]) == dict:\n",
    "#             for key in list(episodes_logs_dict.values())[0][_metrics[idx]][0]:\n",
    "#                 metrics.append(key)\n",
    "#             metrics_to_skip_plotting.add(_metrics[idx])\n",
    "# metrics.append('mean_reward')\n",
    "\n",
    "print(metrics)\n",
    "max_idx = 5e6 # 5e6\n",
    "extra_metrics_to_plot = defaultdict(lambda: nested_dict()) # for storing extra metrics calculated below while looping through standard metrics\n",
    "for metric in metrics:\n",
    "    if metric not in metrics_to_skip_plotting:\n",
    "        plot_dict = nested_dict()\n",
    "        for agent, log in epochs_logs_dict.items():\n",
    "            print(metric)\n",
    "            plot_metric_for_agent = True\n",
    "#             print(log.keys())\n",
    "            if metric in log:\n",
    "                if len(log[metric]) != 0:\n",
    "                    if type(log[metric][0]) == dict:\n",
    "                        # returns broken down into reward sub-components and stored in dict, extract sub-components and calc mean\n",
    "        #                 metrics_to_skip_plotting.add(metric)\n",
    "                        plot_metric_for_agent = False\n",
    "                        for reward_name in log[metric][0].keys():\n",
    "                            # return\n",
    "                            x_vals = np.array([log[metric][idx][reward_name] for idx in range(len(log[metric]))])\n",
    "                            extra_metrics_to_plot[f'R_{reward_name}'][agent]['y_values'] = x_vals[:min(len(x_vals), int(max_idx))]\n",
    "                            extra_metrics_to_plot[f'R_{reward_name}'][agent]['x_values'] = range(len(x_vals[:min(len(x_vals), int(max_idx))]))\n",
    "\n",
    "                            # mean\n",
    "                            x_vals = np.array([log[metric][idx][reward_name]/log['num_steps'][idx] for idx in range(len(log[metric]))])\n",
    "                            extra_metrics_to_plot[f'mean_{reward_name}_reward'][agent]['y_values'] = x_vals[:min(len(x_vals), int(max_idx))]\n",
    "                            extra_metrics_to_plot[f'mean_{reward_name}_reward'][agent]['x_values'] = range(len(x_vals[:min(len(x_vals), int(max_idx))]))\n",
    "                else:\n",
    "                    if metric == 'R' and len(log['num_steps']) != 0:\n",
    "                        # use to calc mean reward\n",
    "                        x_vals = np.array([log[metric][idx]/log['num_steps'][idx] for idx in range(len(log[metric]))])\n",
    "                        extra_metrics_to_plot[f'mean_reward'][agent]['y_values'] = x_vals[:min(len(x_vals), int(max_idx))]\n",
    "                        extra_metrics_to_plot[f'mean_reward'][agent]['x_values'] = range(len(x_vals[:min(len(x_vals), int(max_idx))]))\n",
    "\n",
    "                if metric in log.keys() and plot_metric_for_agent:\n",
    "                    plot_dict[agent]['y_values'] = log[metric][:min(len(log[metric]), int(max_idx))]\n",
    "#                     plot_dict[agent]['x_values'] = list(range(len(log[metric])))[:min(len(log[metric]), int(max_idx))]\n",
    "                    plot_dict[agent]['x_values'] = log['num_ppo_epochs'][:min(len(log[metric]), int(max_idx))]\n",
    "                else:\n",
    "                    print(f'{metric} not tracked for agent {agent} or plt_metric_for_agent is False')\n",
    "            else:\n",
    "                print(f'Metric {metric} not recorded for agent {agent}')\n",
    "\n",
    "    #     # TEMPORARY\n",
    "    #     if metric == 'num_nodes':\n",
    "    #         horizontal_lines = {'strong_branching': 9}\n",
    "#         print(plot_dict)\n",
    "        if metric in ['epsilon']:\n",
    "            moving_average_window = 1\n",
    "        else:\n",
    "            moving_average_window = 100\n",
    "        if plot_raw_data:\n",
    "            _ = sns_plot_val_line(plot_dict,\n",
    "                                  moving_average_window=moving_average_window, # 7 60 200 800\n",
    "                                  plot_unfiltered_data=True, # True\n",
    "        #                           horizontal_lines=horizontal_lines,\n",
    "                                  unfiltered_data_alpha=0.3,\n",
    "                                  xlabel='Epoch',\n",
    "                                  ylabel=metric,\n",
    "                                  ylogscale=ylogscale,\n",
    "                                  show_fig=True)\n",
    "        moving_average_window = int(1)\n",
    "        _ = sns_plot_val_line(plot_dict,\n",
    "        #                           horizontal_lines=horizontal_lines,\n",
    "                                  moving_average_window=moving_average_window, # 10 20 500\n",
    "                                  plot_unfiltered_data=False,\n",
    "                                  xlabel='Epoch',\n",
    "                                  ylabel=metric,\n",
    "                                  ylogscale=ylogscale,\n",
    "                                  show_fig=True)\n",
    "\n",
    "        plot_dicts[metric] = plot_dict\n",
    "        \n",
    "        \n",
    "# plot any extra metrics\n",
    "for metric, plot_dict in extra_metrics_to_plot.items():\n",
    "    print(metric)\n",
    "    print(plot_dict.keys())\n",
    "    if plot_raw_data:\n",
    "        _ = sns_plot_val_line(plot_dict,\n",
    "                              moving_average_window=100, # 7 60 200 800\n",
    "                              plot_unfiltered_data=True, # True\n",
    "                              unfiltered_data_alpha=0.3,\n",
    "                              xlabel='Epoch',\n",
    "                              ylabel=metric,\n",
    "                              ylogscale=ylogscale,\n",
    "                              show_fig=True)\n",
    "\n",
    "    _ = sns_plot_val_line(plot_dict,\n",
    "                          moving_average_window=moving_average_window, # 10 20 500\n",
    "                          plot_unfiltered_data=False,\n",
    "                          xlabel='Epoch',\n",
    "                          ylabel=metric,\n",
    "                          ylogscale=ylogscale,\n",
    "                          show_fig=True)\n",
    "\n",
    "    plot_dicts[metric] = plot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REINFORCE/DQN\n",
    "\n",
    "# epoch metrics\n",
    "%autoreload\n",
    "gamma = 0.99\n",
    "epoch_plot_dicts = {}\n",
    "# metrics = ['R', 'num_nodes', 'solving_time', 'lp_iterations', 'primal_integral', 'dual_integral', 'primal_dual_integral']\n",
    "# metrics = ['loss', 'loss_1', 'loss_2', 'mean_q_value', 'mean_q_value_1', 'mean_q_value_2', 'mean_td_target', 'mean_td_target_1', 'mean_td_target_2', 'mean_reward']\n",
    "# metrics = ['mean_q_value_1', 'mean_q_value_2']\n",
    "\n",
    "metrics_to_skip_plotting = {'agent_name', 'agent_reward', 'agent_device', 'batch_size', 'lr', 'gamma', 'threshold_difficulty', 'learner_name', 'episode_counter', 'epoch_counter', 'gradients', 'num_epochs', 'num_episodes', 'num_actor_steps'}\n",
    "\n",
    "metrics = []\n",
    "for agent_idx in range(len(list(epochs_logs_dict.keys()))):\n",
    "    metrics += [m for m in list(epochs_logs_dict.values())[agent_idx].keys() if m not in metrics_to_skip_plotting and m not in metrics]\n",
    "print(metrics)\n",
    "# metrics = ['agent_pi_entropy', 'q_value']\n",
    "# metrics = ['loss']\n",
    "# for idx in range(len(_metrics)):\n",
    "#     if type(list(episodes_logs_dict.values())[0][_metrics[idx]][0]) == dict:\n",
    "#         for key in list(episodes_logs_dict.values())[0][_metrics[idx]][0]:\n",
    "#             metrics.append(key)\n",
    "#         metrics_to_skip_plotting.add(_metrics[idx])\n",
    "# # metrics.append('mean_reward')\n",
    "# print(f\"(epochs, heads, head values for this epoch): {np.array(list(epochs_logs_dict.values())[0]['td_target_1']).shape}\")\n",
    "# num_heads = len(np.array(list(epochs_logs_dict.values())[0]['td_target_1'])[0])\n",
    "# print(f'num_heads: {num_heads}')\n",
    "num_heads = 1\n",
    "\n",
    "max_idx = 100e3 # 1e6\n",
    "for metric in metrics:\n",
    "    print(metric)\n",
    "    for head in range(num_heads):\n",
    "        plot_dict = nested_dict() # unscaled rewards\n",
    "        for agent, log in epochs_logs_dict.items():\n",
    "            print(agent)\n",
    "            if metric in log.keys():\n",
    "                log[metric] = np.array(log[metric])\n",
    "                print(f'orig shape: {log[metric].shape}')\n",
    "                if len(log[metric].shape) == 2:\n",
    "                    log[metric] = np.expand_dims(log[metric], axis=-2)\n",
    "                if len(log[metric].shape) == 1:\n",
    "                    log[metric] = np.expand_dims(log[metric], axis=-1)\n",
    "                print(f'refactored shape: {log[metric].shape}')\n",
    "                \n",
    "#                 print(len(log[metric][:, 0, 0]))\n",
    "#                 print(log[metric][:, 0, 0])\n",
    "#                 plt.plot(np.array(range(len(log[metric][:, 0, 0]))), log[metric][:, 0, 0])\n",
    "#                 plt.show()\n",
    "                \n",
    "                if head+1 > log[metric].shape[1] and metric != 'loss':\n",
    "                    # no head\n",
    "                    pass\n",
    "                else:\n",
    "\n",
    "        #             if 'mean_q_value' in metric or 'mean_td_target' in metric or 'mean_reward' in metric:\n",
    "        #                 if metric.split('mean_')[-1] in log.keys():\n",
    "        #                     log[metric] = [np.mean(val) for val in log[metric.split('mean_')[-1]]]\n",
    "\n",
    "                    if metric in log.keys():\n",
    "#                         if metric != 'loss' and 'entropy' not in metric:\n",
    "                        if metric != 'loss' and not ('entropy' in metric and 'dqn' in learner):\n",
    "                            if len(log[metric].shape) == 3:\n",
    "                                if log[metric][:, head, :].shape[-1] > 1:\n",
    "                                    # multiple values, take mean\n",
    "                                    y_vals = np.array([np.mean(val) for val in log[metric][:, head]])\n",
    "                                else:\n",
    "                                    print(f'WARNING: Not sure how to handle metric {metric}, handling similar to loss and entropy...')\n",
    "                                    y_vals = log[metric][:, :, head].squeeze()\n",
    "                            else:\n",
    "                                # already single values\n",
    "                                y_vals = log[metric][:, head]\n",
    "                        else:\n",
    "                            y_vals = log[metric][:, :, head].squeeze()\n",
    "                        plot_dict[agent]['y_values'] = y_vals[:min(len(log[metric]), int(max_idx))]\n",
    "                        plot_dict[agent]['x_values'] = np.array(range(len(plot_dict[agent]['y_values'])))\n",
    "                    else:\n",
    "                        print('Metric {} not tracked for agent {}'.format(metric, agent))\n",
    "            \n",
    "            else:\n",
    "                print('Metric {} not tracked for agent {}'.format(metric, agent))\n",
    "\n",
    "        _ = sns_plot_val_line(plot_dict,\n",
    "                              moving_average_window=1, # 7 60 200 800\n",
    "                              plot_unfiltered_data=True,\n",
    "    #                           horizontal_lines=horizontal_lines,\n",
    "                              unfiltered_data_alpha=0.3,\n",
    "                              xlabel='Epoch',\n",
    "                              ylabel=f'head_{head}_{metric}',\n",
    "                              show_fig=True)\n",
    "        _ = sns_plot_val_line(plot_dict,\n",
    "    #                           horizontal_lines=horizontal_lines,\n",
    "                              moving_average_window=moving_average_window, # 10 20 500\n",
    "                              plot_unfiltered_data=False,\n",
    "                              xlabel='Epoch',\n",
    "                              ylabel=f'head_{head}_{metric}',\n",
    "                              show_fig=True)\n",
    "        epoch_plot_dicts[metric] = plot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradients\n",
    "min_idx = 20\n",
    "max_idx = 40e3\n",
    "plot_dicts = defaultdict(lambda: nested_dict())\n",
    "for agent, log in epochs_logs_dict.items():\n",
    "    start_idx = int(min_idx)\n",
    "    end_idx = int(min(len(log['gradients']), int(max_idx)))\n",
    "    \n",
    "    x_vals = np.array(range(start_idx, end_idx))\n",
    "    \n",
    "    plot_dicts['mean_gradient'][agent]['y_values'] = np.array([log['gradients'][epoch][0] for epoch in range(start_idx, end_idx)])\n",
    "    plot_dicts['mean_gradient'][agent]['x_values'] = x_vals\n",
    "    \n",
    "    plot_dicts['min_gradient'][agent]['y_values'] = np.array([log['gradients'][epoch][1] for epoch in range(start_idx, end_idx)])\n",
    "    plot_dicts['min_gradient'][agent]['x_values'] = x_vals\n",
    "    \n",
    "    plot_dicts['max_gradient'][agent]['y_values'] = np.array([log['gradients'][epoch][2] for epoch in range(start_idx, end_idx)])\n",
    "    plot_dicts['max_gradient'][agent]['x_values'] = x_vals\n",
    "    \n",
    "    plot_dicts['std_gradient'][agent]['y_values'] = np.array([log['gradients'][epoch][3] for epoch in range(start_idx, end_idx)])\n",
    "    plot_dicts['std_gradient'][agent]['x_values'] = x_vals\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "for key in plot_dicts.keys():\n",
    "    _ = sns_plot_val_line(plot_dicts[key],\n",
    "                          moving_average_window=100, # 7 60 200 800\n",
    "                          plot_unfiltered_data=True,\n",
    "                          unfiltered_data_alpha=0.3,\n",
    "                          xlabel='Epoch',\n",
    "                          ylabel=key,\n",
    "                          show_fig=True)\n",
    "    \n",
    "    _ = sns_plot_val_line(plot_dicts[key],\n",
    "                          moving_average_window=moving_average_window, # 7 60 200 800\n",
    "                          plot_unfiltered_data=False,\n",
    "                          unfiltered_data_alpha=0.3,\n",
    "                          xlabel='Epoch',\n",
    "                          ylabel=key,\n",
    "                          show_fig=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG\n",
    "\n",
    "## Check if NN params the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "paths = {'gnn_100k': '/scratch/datasets/retro_branching/supervised_learner/gnn/gnn_21/checkpoint_275/',\n",
    "         'cp_1': '/scratch/datasets/retro_branching/reinforce_learner/rl_gnn/rl_gnn_179/checkpoint_1/'}\n",
    "\n",
    "agent_to_params = {}\n",
    "for agent, path in paths.items():\n",
    "#     print(agent)\n",
    "#     print(torch.load(path+'trained_params.pkl'))\n",
    "    agent_to_params[agent] = torch.load(path+'trained_params.pkl')\n",
    "#     print(agent_to_params[agent].values())\n",
    "# print(agent_to_params)\n",
    "\n",
    "for gnn_100k_tensor, cp_1_tensor in zip(agent_to_params['gnn_100k'].values(), agent_to_params['cp_1'].values()):\n",
    "#     print('\\n>>> new tensor <<<')\n",
    "#     print('gnn 100k:')\n",
    "#     print(gnn_100k_tensor)\n",
    "#     print('cp 1:')\n",
    "#     print(cp_1_tensor)\n",
    "    if not torch.equal(gnn_100k_tensor, cp_1_tensor):\n",
    "        raise Exception('not equal')\n",
    "print('all equal')\n",
    "#     print(torch.equal(gnn_100k_tensor, cp_1_tensor))\n",
    "# agent_to_params['gnn_100k']\n",
    "# agent_to_params['cp_1']\n",
    "\n",
    "# params_lists = [list(params) for params in agent_to_params.values()]\n",
    "# print(params_lists)\n",
    "# for gnn_100k_params, cp_1_params in zip(params_lists[0].values(), params_lists[1].values()):\n",
    "#     print(gnn_100k_params)\n",
    "#     print(cp_1_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that all model parameters are finite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/scratch/datasets/retro_branching/supervised_learner/gnn/gnn_151/checkpoint_23/'\n",
    "params = torch.load(path+'trained_params.pkl')\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Curve Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "learner = 'dqn_learner' # 'reinforce_learner' 'dqn_learner'\n",
    "base_name = 'dqn_gnn' # 'rl_gnn' 'dqn_gnn'\n",
    "\n",
    "# learner = 'ppo_learner' # 'reinforce_learner' 'dqn_learner'\n",
    "# base_name = 'ppo' # 'rl_gnn' 'dqn_gnn'\n",
    "\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "logs_dict = nested_dict()\n",
    "action_probabilities_dict = {}\n",
    "\n",
    "metrics = ['num_nodes', 'solving_time', 'lp_iterations']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### REINFORCE ###########\n",
    "# ids = [553] # 432?\n",
    "# ids = [553, 585]\n",
    "# ids = [583, 584, 586]\n",
    "# ids = [589, 590]\n",
    "# ids = [624, 625, 626, 627, 628]\n",
    "# ids = [629, 631, 632, 633, 634]\n",
    "# ids = [639, 641]\n",
    "# ids = [643, 644]\n",
    "# ids = [577, 578]\n",
    "# ids = [633]\n",
    "\n",
    "\n",
    "\n",
    "############# DQN ##########\n",
    "# ids = [1142]\n",
    "# # ids = [1147]\n",
    "# ids = [1226]\n",
    "# # ids = [1168]\n",
    "# # ids = [1222, 1224, 1225, 1227]\n",
    "# # ids = [1226, 1236]\n",
    "# ids = [1236, 1244]\n",
    "# # ids = [1190, 1224, 1225, 1235]\n",
    "# # ids = [1194, 1235]\n",
    "# # ids = [1235]\n",
    "# ids = [1256, 1264, 1265, 1277]\n",
    "# # ids = [1278, 1279, 1280, 1281]\n",
    "# ids = [1278, 1280, 1281]\n",
    "# ids = [1271, 1286, 1287]\n",
    "# ids = [1318, 1319]\n",
    "# ids = [1325, 1355, 1357, 1358]\n",
    "# # ids = [1319, 1325]\n",
    "# ids = [1325, 1357]\n",
    "# ids = [1376, 1377]\n",
    "# # ids = [1236, 1347, 1359]\n",
    "# ids = [1373]\n",
    "# ids = [1373, 1378, 1379, 1380]\n",
    "# ids = [1379]\n",
    "# # ids = [1382]\n",
    "# # ids = [1383]\n",
    "ids = [1390]\n",
    "ids = [1388]\n",
    "ids = [1405, 1236]\n",
    "ids = [1376, 1415, 1414, 1416, 1418]\n",
    "ids = [1407]\n",
    "ids = [1415, 1418, 1414, 1416, 1376, 1424]\n",
    "ids = [1415, 1422, 1423, 1431]\n",
    "# ids = [1415]\n",
    "# ids = [1429, 1428, 1430]\n",
    "# ids = [1376, 1397]\n",
    "ids = [1426]\n",
    "ids = [1436, 1437, 1438, 1439]\n",
    "ids = [1236, 1244]\n",
    "# ids = [1247, 1448, 1450]\n",
    "ids = [1448]\n",
    "# ids = [1451, 1452, 1453, 1454, 1455, 1457]\n",
    "ids = [1458]\n",
    "ids = [1464]\n",
    "ids = [1393]\n",
    "ids = [1470, 1469]\n",
    "\n",
    "# ids = [1484, 1481, 1479]\n",
    "# ids = [1481, 1487]\n",
    "ids = [1481]\n",
    "# ids = [1484]\n",
    "# ids = [1481, 1485]\n",
    "\n",
    "ids = [1491]\n",
    "\n",
    "############# PPO #############\n",
    "# ids = [34]\n",
    "# ids = [34, 65]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in ids:\n",
    "    first_cp, last_cp = None, None\n",
    "    \n",
    "    # get agent reinforce learner folder path\n",
    "    agent = f'{base_name}_{i}'\n",
    "    agent_path = f'/scratch/datasets/retro_branching/{learner}/{base_name}/{agent}/'  \n",
    "    # get saved reinforce learner saved checkpoints\n",
    "    paths = sorted(glob.glob(agent_path+'/checkpoint_*'))\n",
    "    checkpoints = [path.split('/')[-1] for path in paths]\n",
    "\n",
    "    logs_dict[agent]['episode'] = []\n",
    "    for m in metrics:\n",
    "        logs_dict[agent][m] = []\n",
    "    \n",
    "    for metric in metrics:\n",
    "\n",
    "        # search through checkpoints and find if rl_validator/ created for any\n",
    "        for idx, path in enumerate(paths):\n",
    "            if os.path.isdir(path+'/rl_validator'):\n",
    "                # rl validator created for this checkpoint folder, retrieve data for point in validation curve\n",
    "                print(path)\n",
    "                \n",
    "                # get num training episodes completed at this checkpoint\n",
    "                if os.path.exists(agent_path+'database'):\n",
    "                    # log saved to database\n",
    "                    _f = '/episodes_log.sqlite'\n",
    "                else:\n",
    "                    # log saved in separate folders\n",
    "                    if os.path.exists(path+'/episodes_log.pkl'):\n",
    "                        _f = '/episodes_log.pkl'\n",
    "                    else:\n",
    "                        _f = '/*log.pkl'\n",
    "                \n",
    "                # get num training episodes\n",
    "                if _f.split('.')[-1] == '.pkl':\n",
    "                    f = gzip.open(*glob.glob(path+_f), 'rb')\n",
    "                    log = pickle.load(f)\n",
    "                    num_training_episodes = len(log['R'])\n",
    "                else:\n",
    "                    with SqliteDict(agent_path+'/database/episodes_log.sqlite') as _log:\n",
    "                        # get last cp\n",
    "                        last = int(get_most_recent_checkpoint_foldername(agent_path, idx=-1).split('_')[-1])\n",
    "                        # get cp number\n",
    "                        cp = int(path.split('_')[-1])\n",
    "                        num_training_episodes = (int((len(_log['R']) / (last-1))) * (cp-1))\n",
    "#                         num_training_episodes = idx * 500\n",
    "                        # TODO: calc episodes at each checkpoint by taking total num episodes and dividing by total num checkpoints\n",
    "#                         raise Exception('Need to implement method for calculating num episodes at checkpoint for databse')\n",
    "                        _log.close()\n",
    "                \n",
    "                try:\n",
    "                    # get rl_validator/ data for this checkpoint\n",
    "                    path += f'/rl_validator/rl_validator_1/'\n",
    "                    checkpoint = get_most_recent_checkpoint_foldername(path, idx=-1)\n",
    "                    path += '{}/'.format(checkpoint)\n",
    "                    with gzip.open(*glob.glob(path+'*log.pkl'), 'rb') as f:\n",
    "                        log = pickle.load(f) \n",
    "                    print('Loaded validation data from {} (num_training_episodes={})'.format(path, num_training_episodes))\n",
    "                    logs_dict[agent]['episode'] += [num_training_episodes for _ in range(len(log[agent]['num_nodes']))]\n",
    "                    for metric in metrics:\n",
    "                        logs_dict[agent][metric] += [abs(np.sum(rewards)) for rewards in log[agent][metric]]\n",
    "\n",
    "                    if first_cp is None:\n",
    "                        # set first cp\n",
    "                        first_cp = agent+'_'+checkpoints[idx]\n",
    "                        action_probabilities_dict[agent+f'_{checkpoints[idx]}'] = log[agent]['action_probabilities']\n",
    "                    else:\n",
    "                        # update last cp\n",
    "                        if last_cp is None:\n",
    "                            last_cp = checkpoints[idx]\n",
    "                            action_probabilities_dict[agent+f'_{last_cp}'] = log[agent]['action_probabilities']\n",
    "                        else:\n",
    "                            _last_cp = checkpoints[idx]\n",
    "                            if int(_last_cp.split('_')[-1]) > int(last_cp.split('_')[-1]):\n",
    "                                for key in action_probabilities_dict.keys():\n",
    "                                    if key == agent+'_'+last_cp:\n",
    "                                        del action_probabilities_dict[key]\n",
    "                                        break\n",
    "                                last_cp = _last_cp\n",
    "                                action_probabilities_dict[agent+f'_{last_cp}'] = log[agent]['action_probabilities']\n",
    "\n",
    "                except EOFError:\n",
    "                    print('No valid log data in {}'.format(path))\n",
    "            else:\n",
    "                # no rl validator created for this checkpoint folder\n",
    "                pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "\n",
    "# scip_params = 'default'\n",
    "scip_params = 'gasse_2019'\n",
    "\n",
    "\n",
    "# BASELINES\n",
    "\n",
    "# SC\n",
    "co_class = 'set_covering'\n",
    "# co_class_kwargs = {'n_rows': 100, 'n_cols': 100}\n",
    "# co_class_kwargs = {'n_rows': 165, 'n_cols': 230}\n",
    "# co_class_kwargs = {'n_rows': 250, 'n_cols': 500}\n",
    "# co_class_kwargs = {'n_rows': 300, 'n_cols': 500}\n",
    "co_class_kwargs = {'n_rows': 500, 'n_cols': 1000}\n",
    "# co_class_kwargs = {'n_rows': 1000, 'n_cols': 1000}\n",
    "\n",
    "# # CA\n",
    "# co_class = 'combinatorial_auction'\n",
    "# co_class_kwargs = {'n_items': 10, 'n_bids': 50}\n",
    "\n",
    "# # # CFL\n",
    "# co_class = 'capacitated_facility_location'\n",
    "# co_class_kwargs = {'n_customers': 5, 'n_facilities': 5}\n",
    "\n",
    "# # MIS\n",
    "# co_class = 'maximum_independent_set'\n",
    "# co_class_kwargs = {'n_nodes': 25}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "threshold_difficulty = None # None 100\n",
    "# names = ['gnn_21_checkpoint_275']\n",
    "# baselines = [f'/scratch/datasets/retro_branching/instances/set_cover_nrows_{nrows}_ncols_{ncols}_density_005_threshold_{threshold_difficulty}/baselines/{name}' for name in names]\n",
    "baselines = sorted(glob.glob(f'/scratch/datasets/retro_branching/instances/{gen_co_name(co_class, co_class_kwargs)}/baselines/*'))\n",
    "bs = [b.split('/')[-1] for b in baselines]\n",
    "print(f'Baselines available: {bs}')\n",
    "if co_class == 'set_covering':\n",
    "    if co_class_kwargs['n_rows'] == 100 and co_class_kwargs['n_cols'] == 100:\n",
    "        baselines_to_show = ['strong_branching', 'rl_gnn_641_checkpoint_1997', 'gnn_339_checkpoint_90', 'gnn_341_checkpoint_120', 'dqn_gnn_1094_checkpoint_108']\n",
    "    elif co_class_kwargs['n_rows'] == 500 and co_class_kwargs['n_cols'] == 1000:\n",
    "        baselines_to_show = ['gnn_343_checkpoint_233', 'dqn_gnn_1147_checkpoint_64', 'pseudocost', 'strong_branching', 'dqn_gnn_1236_checkpoint_457', 'dqn_gnn_1484_checkpoint_74', 'gnn_361_checkpoint_139']\n",
    "    elif co_class_kwargs['n_rows'] == 165:\n",
    "        baselines_to_show = ['gnn_356_checkpoint_104']\n",
    "    elif co_class_kwargs['n_rows'] == 250:\n",
    "        baselines_to_show = ['pseudocost', 'strong_branching', 'gnn_358_checkpoint_268']\n",
    "    elif co_class_kwargs['n_rows'] == 300:\n",
    "        baselines_to_show = ['gnn_357_checkpoint_173']\n",
    "    elif co_class_kwargs['n_rows'] == 1000:\n",
    "        baselines_to_show = ['gnn_343_checkpoint_233']\n",
    "    else:\n",
    "        raise Exception(f'Unrecognised nrows={co_class_kwargs[\"n_rows\"]} ncols={co_class_kwargs[\"n_cols\"]}')\n",
    "elif co_class == 'combinatorial_auction':\n",
    "    if co_class_kwargs['n_items'] == 10:\n",
    "        baselines_to_show = ['pseudocost', 'strong_branching', 'gnn_347_checkpoint_124']\n",
    "    elif co_class_kwargs['n_items'] == 23:\n",
    "        baselines_to_show = ['pseudocost', 'strong_branching', 'gnn_348_checkpoint_128']\n",
    "    elif co_class_kwargs['n_items'] == 37:\n",
    "        baselines_to_show = ['pseudocost', 'strong_branching', 'gnn_349_checkpoint_98']\n",
    "    else:\n",
    "        raise Exception(f'Unrecognised n_items {co_class_kwargs[\"n_items\"]}')\n",
    "elif co_class == 'capacitated_facility_location':\n",
    "    if co_class_kwargs['n_facilities'] == 5:\n",
    "        baselines_to_show = ['pseudocost', 'strong_branching', 'gnn_350_checkpoint_104']\n",
    "    elif co_class_kwargs['n_facilities'] == 8:\n",
    "        baselines_to_show = ['pseudocost', 'strong_branching', 'gnn_351_checkpoint_69']\n",
    "    elif co_class_kwargs['n_facilities'] == 12:\n",
    "        baselines_to_show = ['pseudocost', 'strong_branching', 'gnn_352_checkpoint_131']\n",
    "    else:\n",
    "        raise Exception(f'Unrecognised n_facilities {co_class_kwargs[\"n_facilities\"]}')\n",
    "elif co_class == 'maximum_independent_set':\n",
    "    if co_class_kwargs['n_nodes'] == 25:\n",
    "        baselines_to_show = ['pseudocost', 'strong_branching', 'gnn_353_checkpoint_209']\n",
    "    elif co_class_kwargs['n_nodes'] == 42:\n",
    "        baselines_to_show = ['pseudocost', 'strong_branching', 'gnn_354_checkpoint_193']\n",
    "    elif co_class_kwargs['n_nodes'] == 58:\n",
    "        baselines_to_show = ['pseudocost', 'strong_branching', 'gnn_355_checkpoint_158']\n",
    "    else:\n",
    "        raise Exception(f'Unrecognised n_nodes {co_class_kwargs[\"n_nodes\"]}')\n",
    "else:\n",
    "    print(f'Not yet configured which baselines to show for co_class {co_class}')\n",
    "\n",
    "print(f'Baselines to show: {baselines_to_show}')\n",
    "baselines_logs_dict = {}\n",
    "for baseline in baselines:\n",
    "    baseline_name = baseline.split('/')[-1]\n",
    "    if baseline_name in baselines_to_show:\n",
    "        baselines_logs_dict[baseline_name] = {}\n",
    "        print(f'\\n{baseline_name}')\n",
    "        path = baseline + '/rl_validator/rl_validator_1/'\n",
    "        path += get_most_recent_checkpoint_foldername(path)\n",
    "        with gzip.open(*glob.glob(path+'/*log.pkl'), 'rb') as f:\n",
    "            log = pickle.load(f)\n",
    "            print(log.keys())\n",
    "            print(log[baseline_name].keys())\n",
    "            for metric in log['metrics']:\n",
    "                baselines_logs_dict[baseline_name][metric] = [abs(np.sum(rewards)) for rewards in log[baseline_name][metric]]\n",
    "                print('{} mean {}: {}'.format(baseline_name, metric, np.mean(baselines_logs_dict[baseline_name][metric])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(action_probabilities_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "plot_dict = nested_dict() # unscaled rewards\n",
    "start_idx = 0 # 0\n",
    "xlim = None\n",
    "# xlim = [50000, 400000]\n",
    "ylim = None\n",
    "# ylim = [0, 200]\n",
    "ylogscale = True\n",
    "for metric in metrics:\n",
    "    for agent, log in logs_dict.items():\n",
    "#         print(len(log[metric]))\n",
    "        plot_dict[agent]['y_values'] = log[metric][start_idx:]\n",
    "        plot_dict[agent]['x_values'] = log['episode'][start_idx:]\n",
    "        \n",
    "#         print(metric, agent, plot_dict[agent]['y_values'][0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # get x value of min and max y value\n",
    "#         min_idx, max_idx = np.argmin(plot_dict[agent]['y_values']), np.argmax(plot_dict[agent]['y_values'])\n",
    "\n",
    "        x_to_y_vals = defaultdict(lambda: [])\n",
    "        for idx, x_val in enumerate(plot_dict[agent]['x_values']):\n",
    "            x_to_y_vals[x_val].append(plot_dict[agent]['y_values'][idx])\n",
    "        for x_val in x_to_y_vals:\n",
    "            x_to_y_vals[x_val] = np.mean(x_to_y_vals[x_val])\n",
    "        min_x_val, max_x_val = min(x_to_y_vals, key=x_to_y_vals.get), max(x_to_y_vals, key=x_to_y_vals.get)\n",
    "        print(f'{agent} y min/max x_val: x={min_x_val},y={round(x_to_y_vals[min_x_val], 2)}/x={max_x_val},y={round(x_to_y_vals[max_x_val], 2)}')\n",
    "        \n",
    "        \n",
    "    horizontal_lines = {baseline: np.mean(log[metric]) for baseline, log in baselines_logs_dict.items()}\n",
    "#     print(f'horizontal lines: {horizontal_lines}')\n",
    "#     horizontal_lines = {}\n",
    "\n",
    "    _ = sns_plot_val_line(plot_dict,\n",
    "                          moving_average_window=None, # 7 60 200 800 None\n",
    "                          plot_unfiltered_data=False,\n",
    "                          horizontal_lines=horizontal_lines,\n",
    "                          unfiltered_data_alpha=0.3,\n",
    "                          xlabel='Training Episode',\n",
    "                          ylabel='Validation (\\u03A3{})'.format(metric),\n",
    "                          ci=68, # None 68 'sd'\n",
    "                          ylogscale=ylogscale,\n",
    "                          xlim=xlim,\n",
    "                          ylim=ylim,\n",
    "                          show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising softmax\n",
    "\n",
    "episode, step = 0, 0\n",
    "\n",
    "x_tick_freq = 5 # frequency with which to draw x-axis labels on graph\n",
    "for agent in action_probabilities_dict.keys():\n",
    "    highest_prob_action = np.argmax(action_probabilities_dict[agent][episode][step])\n",
    "    title = f'Episode {episode} step {step} {agent} argmax action: {highest_prob_action}'\n",
    "    first_step_probs = np.array(action_probabilities_dict[agent][episode][step])\n",
    "    data = pd.DataFrame({'Action': np.arange(len(first_step_probs)), 'Probability': first_step_probs})\n",
    "    ax = sns.barplot(data=data, x='Action', y='Probability', color='c')\n",
    "    for counter, label in enumerate(ax.xaxis.get_ticklabels()):\n",
    "        if counter % x_tick_freq == 0:\n",
    "            label.set_visible(True)\n",
    "        else:\n",
    "            label.set_visible(False) \n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rollout Validation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "# validator_path = '/scratch/datasets/retro_branching/rl_validator/rl_validator_7/' # imitation_100k\n",
    "# validator_path = '/scratch/datasets/retro_branching/rl_validator/rl_validator_11/' # easy (threshold <= 100)\n",
    "# validator_path = '/scratch/datasets/retro_branching/rl_validator/rl_validator_12/' # hard (100 <= threshold)\n",
    "# validator_path = '/scratch/datasets/retro_branching/rl_validator/rl_validator_13/' # all (threshold = None)\n",
    "# validator_path = '/scratch/datasets/retro_branching/rl_validator/rl_validator_15/' # easy (threshold <= 100) but w/ cp 1 and latest\n",
    "# validator_path = '/scratch/datasets/retro_branching/rl_validator/rl_validator_25/'\n",
    "# validator_path = '/scratch/datasets/retro_branching/rl_validator/rl_validator_37/'\n",
    "# validator_path = '/scratch/datasets/retro_branching/rl_validator/rl_validator_73/' # 39 44 47 54 58 64 69\n",
    "# validator_path = '/scratch/datasets/retro_branching/rl_validator/rl_validator_80/' # SB score imitation\n",
    "# validator_path = '/scratch/datasets/retro_branching/rl_validator/rl_validator_83/' # 81 83 where does learning stop investigation 553\n",
    "# validator_path = '/scratch/datasets/retro_branching/rl_validator/rl_validator_84/'\n",
    "validator_path = '/scratch/datasets/retro_branching/rl_validator/rl_validator_85/'\n",
    "foldername = get_most_recent_checkpoint_foldername(validator_path)\n",
    "path = '{}{}/'.format(validator_path, foldername)\n",
    "print(path)\n",
    "with gzip.open(*glob.glob(path+'*log.pkl'), 'rb') as f:\n",
    "    episodes_log = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "plot_dicts = {metric: nested_dict() for metric in episodes_log['metrics']}\n",
    "\n",
    "for agent in episodes_log['agent_names']:\n",
    "    if agent not in []:\n",
    "        for metric in episodes_log['metrics']:\n",
    "#             plot_dicts[metric][agent]['y_values'] = episodes_log[agent][metric]\n",
    "#             plot_dicts[metric][agent]['x_values'] = list(range(len(episodes_log[agent][metric])))\n",
    "            returns = [abs(np.sum(rewards)) for rewards in episodes_log[agent][metric]]\n",
    "#             print('agent: {} | metric: {} | rewards: {} | total abs(return)s: {}'.format(agent, metric, episodes_log[agent][metric], returns))\n",
    "            plot_dicts[metric][agent]['y_values'] = returns\n",
    "            plot_dicts[metric][agent]['x_values'] = list(range(len(returns)))\n",
    "        \n",
    "res = 1\n",
    "for metric in plot_dicts.keys():\n",
    "    _ = plot_val_line(plot_dicts[metric],\n",
    "                      xlabel='Episode',\n",
    "                      ylabel='{}'.format(metric),\n",
    "                      show_fig=True)\n",
    "    _ = plot_val_line(plot_dicts[metric],\n",
    "                      xlabel='Episode',\n",
    "                      ylabel='Mean {}'.format(metric),\n",
    "                      smooth_data_res=res,\n",
    "                      show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot action probabilities for first decision in episode\n",
    "import pandas as pd\n",
    "\n",
    "x_tick_freq = 5 # frequency with which to draw x-axis labels on graph\n",
    "for agent in episodes_log['agent_names']:\n",
    "    if agent not in ['pc', 'random']:\n",
    "        episode, step = 0, 0\n",
    "        highest_prob_action = np.argmax(episodes_log[agent]['action_probabilities'][episode][step])\n",
    "        title = f'Episode {episode} step {step} {agent} argmax action: {highest_prob_action}'\n",
    "        first_step_probs = np.array(episodes_log[agent]['action_probabilities'][episode][step])\n",
    "        data = pd.DataFrame({'Action': np.arange(len(first_step_probs)), 'Probability': first_step_probs})\n",
    "        ax = sns.barplot(data=data, x='Action', y='Probability', color='c')\n",
    "        # filter x-axis labels to prevent label overlapping\n",
    "        for counter, label in enumerate(ax.xaxis.get_ticklabels()):\n",
    "            if counter % x_tick_freq == 0:\n",
    "                label.set_visible(True)\n",
    "            else:\n",
    "                label.set_visible(False)  \n",
    "        plt.title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Agent Learning Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import io\n",
    "epochs_logs_dict = {}\n",
    "# ids = [21]\n",
    "# ids = [43, 34, 33, 35, 30, 29]\n",
    "# ids = [21, 37, 38, 39, 40, 42]\n",
    "# ids = [37, 38, 39, 40, 42]\n",
    "# ids = [21, 52, 48, 49, 50, 51] # new architectures geneva\n",
    "# ids = [21, 53, 54, 55, 56, 57] # new architectures mammoth\n",
    "# ids = [112] # imitation_target='expert_scores'\n",
    "# ids = [139]\n",
    "# ids = [185]\n",
    "\n",
    "# ids = [176, 177] # sb score imitation, small\n",
    "# ids = [184, 235] # sb rank imitation, small\n",
    "\n",
    "# ids = [250, 252, 246] # sb rank imitation, large, alpha=0.2\n",
    "# ids = [260, 261] # sb rank imitation, large, alpha=0.5\n",
    "# ids = [258, 259] # sb score imitation, large\n",
    "# ids = [265, 266] # sb score imitation w/ loss_function=KLDivergence()\n",
    "\n",
    "# ids = [291, 292] # predicting agent_reward=num_nodes, gamma=0, 100x100\n",
    "# ids = [295, 297] # predicting agent_reward=num_nodes, gamma=0.99, 100x100\n",
    "# ids = [290, 293] # predicting agent_reward=dual_bound_frac, gamma=0, 100x100\n",
    "# ids = [296, 298] # predicting agent_reward=dual_bound_frac, gamma=0.99, 100x100\n",
    "\n",
    "ids = [299, 300, 301, 302] # predicting agent_reward=dual_bound_frac, gamma=0.99, 500x1000\n",
    "\n",
    "ids = [308]\n",
    "ids = [311, 312, 313]\n",
    "ids = [312, 315, 316]\n",
    "ids = [317, 319]\n",
    "\n",
    "ids = [321]\n",
    "ids = [322] # expert scores (gamma=0, obviously)\n",
    "# ids = [326] # expert_score, gamma=0\n",
    "# ids = [328, 330] # expert_score, gamma=0.99\n",
    "\n",
    "# ids = [335, 336] # normalised_lp_gain, gamma=0\n",
    "ids = [338] # gasse et al. 100x100\n",
    "# ids = [339] # gasse et al. 100x100 w/ our network\n",
    "# ids = [338, 339]\n",
    "ids = [338, 341]\n",
    "ids = [21, 343]\n",
    "# ids = [343]\n",
    "ids = [345]\n",
    "ids = [347, 348, 349]\n",
    "ids = [350, 351, 352]\n",
    "ids = [353, 354, 355]\n",
    "\n",
    "ids = [356] # 165x230 set cover\n",
    "ids = [357] # 300x500 set cover\n",
    "ids = [358] # 250x500 set cover\n",
    "\n",
    "# ids = [361, 364, 365] # 500x1000 set cover scip_params=gasse_2019\n",
    "ids = [364, 365]\n",
    "\n",
    "\n",
    "epochs = [0] # tracking interesting epochs to plot softmax\n",
    "for i in ids:\n",
    "    agent = 'gnn_{}'.format(i)\n",
    "#     agent_path = '../scripts/supervised_learner/gnn/{}/'.format(agent)\n",
    "    agent_path = '/scratch/datasets/retro_branching/supervised_learner/gnn/{}/'.format(agent)\n",
    "    foldername = get_most_recent_checkpoint_foldername(agent_path, idx=-1)\n",
    "    path = '{}{}/'.format(agent_path, foldername)\n",
    "    print(path)\n",
    "    with gzip.open(*glob.glob(path+'*log.pkl'), 'rb') as f:\n",
    "        epochs_log = pickle.load(f)\n",
    "#         epochs_log = torch.load(io.BytesIO(pickle.dumps(pickle.load(f))), map_location='cpu')\n",
    "#         epochs_log = torch.load(f, map_location='cpu', pickle_module=pickle)\n",
    "    epochs_logs_dict[agent] = epochs_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "plot_dict = nested_dict()\n",
    "for agent, epochs_log in epochs_logs_dict.items():\n",
    "    plot_dict[agent]['y_values'] = epochs_log['mean_train_loss']\n",
    "    plot_dict[agent]['x_values'] = list(range(len(epochs_log['mean_train_loss'])))\n",
    "_ = sns_plot_val_line(plot_dict,\n",
    "                      moving_average_window=None,\n",
    "                      plot_unfiltered_data=True,\n",
    "                      unfiltered_data_alpha=0.3,\n",
    "                      xlabel='Epoch',\n",
    "                      ylabel='Training Loss',\n",
    "                      show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "plot_dict = nested_dict()\n",
    "for agent, epochs_log in epochs_logs_dict.items():\n",
    "    plot_dict[agent]['y_values'] = epochs_log['mean_train_acc']\n",
    "    plot_dict[agent]['x_values'] = list(range(len(epochs_log['mean_train_acc'])))\n",
    "_ = sns_plot_val_line(plot_dict,\n",
    "                      moving_average_window=1,\n",
    "                      plot_unfiltered_data=True,\n",
    "                      unfiltered_data_alpha=0.3,\n",
    "                      xlabel='Epoch',\n",
    "                      ylabel='Training Accuracy',\n",
    "                      show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "plot_dict = nested_dict()\n",
    "for agent, epochs_log in epochs_logs_dict.items():\n",
    "    plot_dict[agent]['y_values'] = epochs_log['mean_valid_loss']\n",
    "    plot_dict[agent]['x_values'] = list(range(len(epochs_log['mean_valid_loss'])))\n",
    "    min_idx, max_idx = np.argmin(plot_dict[agent]['y_values']), np.argmax(plot_dict[agent]['y_values'])\n",
    "    print('{} min/max idx(xval): {}(x={})/{}(x={})'.format(agent, min_idx, plot_dict[agent]['x_values'][min_idx], max_idx, plot_dict[agent]['x_values'][max_idx]))\n",
    "    epochs.append(min_idx)\n",
    "_ = sns_plot_val_line(plot_dict,\n",
    "                      moving_average_window=2,\n",
    "                      plot_unfiltered_data=True,\n",
    "                      unfiltered_data_alpha=0.3,\n",
    "                      xlabel='Epoch',\n",
    "                      ylabel='Validation Loss',\n",
    "                      show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "plot_dict = nested_dict()\n",
    "for agent, epochs_log in epochs_logs_dict.items():\n",
    "    plot_dict[agent]['y_values'] = epochs_log['mean_valid_acc']\n",
    "    plot_dict[agent]['x_values'] = list(range(len(epochs_log['mean_valid_acc'])))\n",
    "_ = sns_plot_val_line(plot_dict,\n",
    "                      moving_average_window=10,\n",
    "                      plot_unfiltered_data=True,\n",
    "                      unfiltered_data_alpha=0.3,\n",
    "                      xlabel='Epoch',\n",
    "                      ylabel='Validation Accuracy',\n",
    "                      show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from scipy import spatial\n",
    "\n",
    "def none_activation(_input):\n",
    "    return _input\n",
    "\n",
    "sns.set_context(context='paper')\n",
    "sns.set_style(style='whitegrid')\n",
    "fig = plt.figure()\n",
    "\n",
    "x_tick_freq = 5 # frequency with which to draw x-axis labels on graph\n",
    "# epochs = sorted([0, 133, 90, 60]) # which epochs to look at\n",
    "batch, sample = 0, 3 # which sample within which batch to look at across epochs\n",
    "epoch_mode = 'valid' # 'train' 'valid' (which epoch mode you want to look at. N.B. If DataLoader shuffles data, epoch batch samples will be different so can't easily compare softmax evolution)\n",
    "imitation_target = 'expert_scores' # 'expert_scores' 'expert_bipartite_ranking'\n",
    "\n",
    "\n",
    "\n",
    "if imitation_target == 'expert_scores':\n",
    "    expert_activation = F.softmax # F.softmax F.sigmoid none_activation\n",
    "    gnn_activation = F.softmax # F.softmax F.sigmoid none_activation\n",
    "    ylabel = 'Softmax' # 'Softmax' 'Sigmoid'\n",
    "elif imitation_target == 'expert_bipartite_ranking':\n",
    "    expert_activation = none_activation # F.softmax F.sigmoid none_activation\n",
    "    gnn_activation = F.sigmoid # F.softmax F.sigmoid none_activation\n",
    "    ylabel = 'Sigmoid' # 'Softmax' 'Sigmoid'\n",
    "\n",
    "for agent, epochs_log in epochs_logs_dict.items():\n",
    "    num_epochs = len(epochs_log[f'{epoch_mode}_logits'])\n",
    "    print(f'Agent {agent} number of epochs: {num_epochs}')\n",
    "    for epoch in epochs:\n",
    "        if epoch > num_epochs-1:\n",
    "            print('Epoch {} > num_epochs={} for agent {}'.format(epoch, num_epochs, agent))\n",
    "        else:\n",
    "            if len(epochs_log[f'{epoch_mode}_logits'][epoch]) > 0:\n",
    "                # get probabilities for valid candidate actions at given sample in a given batch of a given epoch\n",
    "#                 num_candidates = len(epochs_log[f'{epoch_mode}_logits'][epoch][batch][sample])\n",
    "                num_candidates = epochs_log[f'{epoch_mode}_nb_candidates'][epoch][batch][sample]\n",
    "                gnn_probs = gnn_activation(epochs_log[f'{epoch_mode}_logits'][epoch][batch][sample][:num_candidates]).detach().cpu().numpy()\n",
    "                expert_probs = expert_activation(epochs_log[f'{epoch_mode}_target'][epoch][batch][sample][:num_candidates]).detach().cpu().numpy()\n",
    "\n",
    "                # gen labels for each data point\n",
    "                gnn_labels = [agent for _ in range(len(gnn_probs))]\n",
    "                expert_labels = ['expert' for _ in range(len(expert_probs))]\n",
    "\n",
    "                # put data into dataframe and construct seaborn bar chart\n",
    "                data = pd.DataFrame({'Action': [*range(len(gnn_probs)), *range(len(expert_probs))], ylabel: [*gnn_probs, *expert_probs], 'Agent': [*gnn_labels, *expert_labels]})\n",
    "                g = sns.catplot(data=data, kind='bar', x='Action', y=ylabel, hue='Agent')\n",
    "\n",
    "                # filter x-axis labels to prevent label overlapping\n",
    "                for counter, label in enumerate(g.ax.xaxis.get_ticklabels()):\n",
    "                    if counter % x_tick_freq == 0:\n",
    "                        label.set_visible(True)\n",
    "                    else:\n",
    "                        label.set_visible(False)  \n",
    "\n",
    "                # calc jensen-shannon distance between gnn and target and display in plot's title\n",
    "                jsd = spatial.distance.jensenshannon(gnn_probs, expert_probs)\n",
    "                title = f'Mode {epoch_mode} epoch {epoch} batch {batch} sample {sample} agent {agent}: JSD={round(jsd, 3)}'\n",
    "                plt.title(title)\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "            else:\n",
    "                print('No logits recorded for agent {} epoch {}'.format(agent, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "a = [i for i in range(64)]\n",
    "t = time.time()\n",
    "if 513 in a:\n",
    "    pass\n",
    "print(f'Total time: {(time.time() - t)*1e3:.3f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = set()\n",
    "indices.add(1)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [2, 3, 4]\n",
    "a[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_epoch = 3.5 / 1000 # takes 3.5s to save 1k epochs\n",
    "num_epochs = 340000\n",
    "checkpoint_freq = 8000\n",
    "\n",
    "num_saves = int(num_epochs/checkpoint_freq)\n",
    "print(f'num cps: {num_saves}')\n",
    "epochs_being_saved = [epochs for epochs in range(checkpoint_freq, num_epochs+checkpoint_freq, checkpoint_freq)]\n",
    "print(epochs_being_saved)\n",
    "cp_save_times = [epochs*time_per_epoch for epochs in epochs_being_saved]\n",
    "print(cp_save_times)\n",
    "print(f'total save time: {sum(cp_save_times)} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen Curriculum Schedule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_val, end_val = 100, 500\n",
    "num_classes = 4\n",
    "\n",
    "diff = end_val - start_val\n",
    "delta = diff / (num_classes - 1)\n",
    "vals = [start_val+(i*delta) for i in range(num_classes)]\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def constr1(x, y):\n",
    "    val = (3*x) - (5*y)\n",
    "    return val, val <= 0\n",
    "\n",
    "def constr2(x, y):\n",
    "    val = (3*x) + (5*y)\n",
    "    return val, val <= 15\n",
    "\n",
    "def obj(x, y):\n",
    "    return (-2 * x) - y\n",
    "\n",
    "x_dual = 2.5\n",
    "y_dual = 1.5\n",
    "\n",
    "print(f'dual sol: x={x_dual}, y={y_dual} -> obj={obj(x_dual, y_dual)}')\n",
    "\n",
    "x = math.floor(x_dual)\n",
    "y = math.floor(y_dual)\n",
    "print(f'\\nP1: x={x}, y={y}')\n",
    "print(f'constr1 x={x} y={y}: {constr1(x, y)}')\n",
    "print(f'constr2 x={x} y={y}: {constr2(x, y)}')\n",
    "print(f'P1 obj: {obj(x, y)}')\n",
    "\n",
    "x = math.ceil(x_dual)\n",
    "y = math.floor(y_dual)\n",
    "print(f'\\nP2: x={x}, y={y}')\n",
    "print(f'constr1 x={x} y={y}: {constr1(x, y)}')\n",
    "print(f'constr2 x={x} y={y}: {constr2(x, y)}')\n",
    "print(f'P2 obj: {obj(x, y)}')\n",
    "\n",
    "x = math.floor(x_dual)\n",
    "y = math.ceil(y_dual)\n",
    "print(f'\\nP3: x={x}, y={y}')\n",
    "print(f'constr1 x={x} y={y}: {constr1(x, y)}')\n",
    "print(f'constr2 x={x} y={y}: {constr2(x, y)}')\n",
    "print(f'P3 obj: {obj(x, y)}')\n",
    "\n",
    "x = math.ceil(x_dual)\n",
    "y = math.ceil(y_dual)\n",
    "print(f'\\nP4: x={x}, y={y}')\n",
    "print(f'constr1 x={x} y={y}: {constr1(x, y)}')\n",
    "print(f'constr2 x={x} y={y}: {constr2(x, y)}')\n",
    "print(f'P4 obj: {obj(x, y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "SystemError: <built-in method __contains__ of dict object at 0x7fbb111b7cd0> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4039d98168f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mecole\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/zciccwf/py36/envs/rlgnn/lib/python3.7/site-packages/ecole/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mecole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspawn_random_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mecole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: SystemError: <built-in method __contains__ of dict object at 0x7fbb111b7cd0> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "import ecole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlgnn",
   "language": "python",
   "name": "rlgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
