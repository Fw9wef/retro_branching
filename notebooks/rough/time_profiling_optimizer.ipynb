{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In time profile, noticed `optimizer.step()` was taking 25% of time, most of which was from `Batch.from_data_list()`. Using this notebook to try investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/zciccwf/py36/envs/rlgnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/scratch/zciccwf/py36/envs/rlgnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/scratch/zciccwf/py36/envs/rlgnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/scratch/zciccwf/py36/envs/rlgnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/scratch/zciccwf/py36/envs/rlgnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/scratch/zciccwf/py36/envs/rlgnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "# %load_ext snakeviz\n",
    "\n",
    "%autoreload\n",
    "from retro_branching.environments import EcoleBranching, EcoleConfiguring\n",
    "from retro_branching.agents import StrongBranchingAgent, PseudocostBranchingAgent\n",
    "from retro_branching.utils import seed_stochastic_modules_globally\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Batch, Data\n",
    "\n",
    "import ecole\n",
    "\n",
    "from os import path\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "from collections import defaultdict, deque, namedtuple\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "\n",
    "seed = 0\n",
    "seed_stochastic_modules_globally(default_seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at `buffer.sample()` time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimial implementation of replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch geoemtric data object for states\n",
    "class BipartiteNodeData(torch_geometric.data.Data):\n",
    "    \"\"\"\n",
    "    This class encode a node bipartite graph observation as returned by the `ecole.observation.NodeBipartite` \n",
    "    observation function in a format understood by the pytorch geometric data handlers.\n",
    "    \"\"\"\n",
    "    def __init__(self, obs, candidates):\n",
    "        super().__init__()\n",
    "        self.obs = obs\n",
    "        self.constraint_features = torch.FloatTensor(obs.row_features)\n",
    "        self.edge_index = torch.LongTensor(obs.edge_features.indices.astype(np.int64))\n",
    "        self.edge_attr = torch.FloatTensor(obs.edge_features.values).unsqueeze(1)\n",
    "        self.variable_features = torch.FloatTensor(obs.column_features)\n",
    "        self.candidates = torch.from_numpy(candidates.astype(np.int64)).long()\n",
    "        self.raw_candidates = torch.from_numpy(candidates.astype(np.int64)).long()\n",
    "        \n",
    "        self.num_candidates = len(candidates)\n",
    "        self.num_variables = self.variable_features.size(0)\n",
    "        self.num_nodes = self.constraint_features.size(0) + self.variable_features.size(0)\n",
    "\n",
    "    def __inc__(self, key, value):\n",
    "        \"\"\"\n",
    "        We overload the pytorch geometric method that tells how to increment indices when concatenating graphs \n",
    "        for those entries (edge index, candidates) for which this is not obvious. This\n",
    "        enables batching.\n",
    "        \"\"\"\n",
    "        if key == 'edge_index':\n",
    "            # constraint nodes connected via edge to variable nodes\n",
    "            return torch.tensor([[self.constraint_features.size(0)], [self.variable_features.size(0)]])\n",
    "        elif key == 'candidates':\n",
    "            # actions are variable nodes\n",
    "            return self.variable_features.size(0)\n",
    "        else:\n",
    "            return super().__inc__(key, value)\n",
    "\n",
    "Transition = namedtuple('Transition', field_names=['state', 'action', 'reward', 'done',  'next_state'])\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, \n",
    "                 capacity):\n",
    "        '''\n",
    "        Args:\n",
    "            capacity (int): Maximum capacity of replay buffer.\n",
    "        '''\n",
    "        # init experience replay buffer\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        for _ in range(capacity):\n",
    "            self.buffer.append(None)\n",
    "        self.curr_write_idx, self.available_samples = 0, 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.available_samples\n",
    "\n",
    "    def append(self, transition):\n",
    "        self.buffer[self.curr_write_idx] = transition\n",
    "\n",
    "        # update write idx\n",
    "        self.curr_write_idx += 1\n",
    "        if self.curr_write_idx >= self.capacity:\n",
    "            # reset to start overwriting old experiences\n",
    "            self.curr_write_idx = 0\n",
    "\n",
    "        # max out the available samples at the memory buffer size\n",
    "        self.available_samples = min(self.available_samples+1, self.capacity)\n",
    "\n",
    "    def sample(self, batch_size, per_beta=None):\n",
    "        # standard experience replay with random uniform sampling\n",
    "        indices = np.random.choice(len(self.buffer[:self.available_samples]), batch_size, replace=False)\n",
    "\n",
    "        # collect the sampled transitions \n",
    "        state, action, reward, done, next_state = zip(*[self.buffer[idx] for idx in indices])\n",
    "\n",
    "        return (Batch.from_data_list(copy.deepcopy(state)),\n",
    "                torch.tensor(copy.deepcopy(action)),\n",
    "                torch.tensor(copy.deepcopy(reward)),\n",
    "                torch.tensor(copy.deepcopy(done)).float(),\n",
    "                Batch.from_data_list(copy.deepcopy(next_state)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init agent, env, and instances\n",
    "agent = StrongBranchingAgent()\n",
    "\n",
    "env = EcoleBranching(observation_function='43_var_features',\n",
    "                      information_function='default',\n",
    "                      reward_function='default',\n",
    "                      scip_params='default')\n",
    "env.seed(seed)\n",
    "\n",
    "instances = ecole.instance.SetCoverGenerator(n_rows=100, n_cols=100, density=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fill buffer with experiences\n",
    "buffer = ReplayBuffer(capacity=128)\n",
    "\n",
    "env_ready = False\n",
    "total_env_step_time = 0\n",
    "while len(buffer) < buffer.capacity:\n",
    "    while not env_ready:\n",
    "        # find instance not pre-solved by the environment\n",
    "        env.seed(seed)\n",
    "        instance = next(instances)\n",
    "        agent.before_reset(instance)\n",
    "        obs, action_set, reward, done, info = env.reset(instance)\n",
    "        if obs is not None:\n",
    "            env_ready = True\n",
    "            state = BipartiteNodeData(obs, action_set).to('cpu')\n",
    "        \n",
    "    # store prev transition params\n",
    "    prev_obs, prev_action_set, prev_state = copy.deepcopy(obs), copy.deepcopy(action_set), copy.deepcopy(state)\n",
    "        \n",
    "    # get  branching action\n",
    "    action, action_idx = agent.action_select(action_set, env.model, done)\n",
    "    \n",
    "    # take step in environment\n",
    "    start = time.time()\n",
    "    obs, action_set, reward, done, info = env.step(action)\n",
    "    total_env_step_time += (time.time() - start)\n",
    "    \n",
    "    if done:\n",
    "        # solved instance, avoid None values in buffer\n",
    "        obs = copy.deepcopy(prev_obs)\n",
    "        action_set = copy.deepcopy(prev_action_set)\n",
    "        env_ready = False\n",
    "    \n",
    "    # add transition to buffer\n",
    "    state = BipartiteNodeData(obs, action_set).to('cpu')\n",
    "    buffer.append(Transition(prev_state, action.item(), reward['normalised_lp_gain'], done, state))\n",
    "    print(f'Buffer size: {len(buffer)}/{buffer.capacity}')\n",
    "    \n",
    "print(f'Total env step time when collection {len(buffer)} samples: {total_env_step_time:.3f} s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample batch of experiences\n",
    "batch_size = 128\n",
    "start = time.time()\n",
    "# %snakeviz state, action, reward, done, next_state = buffer.sample(batch_size)\n",
    "state, action, reward, done, next_state = buffer.sample(batch_size)\n",
    "print(f'Time to sample {batch_size} samples from buffer: {time.time()-start:.3f} s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at `learner.step_optimizer()` time\n",
    "\n",
    "Snakeviz time profiler seemed to suggest that, for large 500x1000 instances, the bottleneck is in some list comprehension statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "torch.Size([128000])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "num_heads = 1\n",
    "num_logits = 128000\n",
    "num_agents = 2\n",
    "\n",
    "logits = [[torch.randn(num_logits, device='cuda:1') for _ in range(num_heads)] for _ in range(num_agents)]\n",
    "print(len(logits))\n",
    "print(len(logits[0]))\n",
    "print(logits[0][0].shape)\n",
    "print(logits[0][0].get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_head_logits_across_agents(logits):\n",
    "    '''\n",
    "    Given a list of lists, where logits[agent_idx][head_idx] is a tensor of agent head outputs,\n",
    "    finds the minimum between each agent_idx's head outputs and returns\n",
    "    the minimum logits for each head as a list of tensors.\n",
    "    '''\n",
    "    min_logits = []\n",
    "    for head in range(len(logits[0])):\n",
    "        head_logits = []\n",
    "        for agent_idx in range(len(logits)):\n",
    "            head_logits.append(logits[agent_idx][head])\n",
    "        min_logits.append(torch.stack(head_logits, dim=-1).min(dim=-1))\n",
    "    logits = [_logits.values for _logits in min_logits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.18 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "36.4 µs ± 27.6 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n10 find_min_head_logits_across_agents(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "         aten::stack        17.95%      34.998us        70.82%     138.042us     138.042us       6.144us        37.50%      13.312us      13.312us             1  \n",
      "           aten::cat         7.02%      13.680us        45.67%      89.015us      89.015us       4.096us        25.00%       7.168us       7.168us             1  \n",
      "          aten::_cat        25.59%      49.879us        38.65%      75.335us      75.335us       3.072us        18.75%       3.072us       3.072us             1  \n",
      "           aten::min        23.68%      46.160us        29.18%      56.888us      56.888us       3.072us        18.75%       3.072us       3.072us             1  \n",
      "     aten::unsqueeze         2.61%       5.094us         6.06%      11.812us      11.812us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "    aten::as_strided         3.45%       6.718us         3.45%       6.718us       6.718us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "     aten::unsqueeze         0.59%       1.158us         1.14%       2.217us       2.217us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "    aten::as_strided         0.54%       1.059us         0.54%       1.059us       1.059us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "         aten::empty         7.01%      13.655us         7.01%      13.655us      13.655us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "       aten::resize_         6.05%      11.801us         6.05%      11.801us      11.801us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "         aten::empty         0.98%       1.910us         0.98%       1.910us       1.910us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "         aten::empty         0.39%       0.768us         0.39%       0.768us       0.768us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "       aten::resize_         1.74%       3.391us         1.74%       3.391us       3.391us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "    aten::as_strided         0.45%       0.869us         0.45%       0.869us       0.869us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "       aten::resize_         1.56%       3.037us         1.56%       3.037us       3.037us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "    aten::as_strided         0.39%       0.753us         0.39%       0.753us       0.753us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 194.930us\n",
      "Self CUDA time total: 16.384us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    find_min_head_logits_across_agents(logits)\n",
    "print(prof.table(sort_by='cuda_time_total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlgnn",
   "language": "python",
   "name": "rlgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
