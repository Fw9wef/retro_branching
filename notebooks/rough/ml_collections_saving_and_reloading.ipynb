{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out ml_collections.ConfigDict() to make saving and reloading agent and network objects easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "\n",
    "cfg = ml_collections.ConfigDict()\n",
    "cfg.float_field = 12.6\n",
    "cfg.integer_field = 123\n",
    "cfg.another_integer_field = 234\n",
    "cfg.nested = ml_collections.ConfigDict()\n",
    "cfg.nested.string_field = 'tom'\n",
    "\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from retro_branching.agents import REINFORCEAgent\n",
    "from retro_branching.networks import BipartiteGCN\n",
    "\n",
    "policy_network = BipartiteGCN(device='cpu',\n",
    "                           emb_size=64,\n",
    "                           num_rounds=1,\n",
    "                           cons_nfeats=5,\n",
    "                           edge_nfeats=1,\n",
    "                           var_nfeats=20, # 19 20 (if using filter network)\n",
    "                           aggregator='add')\n",
    "filter_network = BipartiteGCN(device='cpu',\n",
    "                              emb_size=128,\n",
    "                              num_rounds=2,\n",
    "                              cons_nfeats=5,\n",
    "                              edge_nfeats=1,\n",
    "                              var_nfeats=19,\n",
    "                              aggregator='mean')\n",
    "rlgnn_agent = REINFORCEAgent(policy_network=policy_network, \n",
    "                             filter_network=filter_network,\n",
    "                             device='cpu', \n",
    "                             temperature=1.0,\n",
    "                             name='rl_gnn',\n",
    "                             filter_method='method_2')\n",
    "\n",
    "rlgnn_config = rlgnn_agent.create_config()\n",
    "print(rlgnn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_rlgnn_config = rlgnn_config.to_json_best_effort()\n",
    "print(json_rlgnn_config)\n",
    "\n",
    "with open('rl_gnn_config.json', 'w') as f:\n",
    "    json.dump(json_rlgnn_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "\n",
    "with open('rl_gnn_config.json', 'r') as f:\n",
    "    json_config = json.load(f)\n",
    "    config = ml_collections.ConfigDict(json.loads(json_config))\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "loaded_agent = REINFORCEAgent(device='cpu',\n",
    "                              config='rl_gnn_config.json')\n",
    "print(loaded_agent.policy_network.var_nfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating, saving, and loading config.json for networks and agents\n",
    "\n",
    "Some older networks we've saved only had .pkl state dict of network saved rather than above ml_collections JSON, which is cumbersome to re-initialise each time you want to load the model. Use the below to generate and save ml_collections JSON configs for these networks so can easily re-initialise there after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from retro_branching.networks import BipartiteGCN\n",
    "from retro_branching.agents import REINFORCEAgent\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import ml_collections\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_networks = {f'gnn_{i}': {'checkpoints': 'all', # np.arange(1, 225, 25)\n",
    "                               'emb_size': 64,\n",
    "                               'num_rounds': 1,\n",
    "                               'cons_nfeats': 5,\n",
    "                               'edge_nfeats': 1,\n",
    "                               'var_nfeats': 19,\n",
    "                               'aggregator': 'add'} for i in [1]}\n",
    "\n",
    "for gnn in graph_networks.keys():\n",
    "    if graph_networks[gnn]['checkpoints'] == 'all':\n",
    "        # load all checkpoints\n",
    "        path = f'/scratch/datasets/retro_branching/supervised_learner/gnn/{gnn}/'\n",
    "        graph_networks[gnn]['checkpoints'] = [int(p.split('/')[-1].split('_')[-1]) for p in glob.glob(path+'checkpoint_*')]\n",
    "        \n",
    "    for cp in graph_networks[gnn]['checkpoints']:\n",
    "        # load gnn from state dict\n",
    "        foldername = path + f'/checkpoint_{cp}'\n",
    "        graph_network = BipartiteGCN(device,\n",
    "                                    emb_size=graph_networks[gnn]['emb_size'],\n",
    "                                    num_rounds=graph_networks[gnn]['num_rounds'],\n",
    "                                    cons_nfeats=graph_networks[gnn]['cons_nfeats'],\n",
    "                                    edge_nfeats=graph_networks[gnn]['edge_nfeats'],\n",
    "                                    var_nfeats=graph_networks[gnn]['var_nfeats'],\n",
    "                                    aggregator=graph_networks[gnn]['aggregator'])\n",
    "        graph_network.load_state_dict(torch.load(f'/scratch/datasets/retro_branching/supervised_learner/gnn/{gnn}/checkpoint_{cp}/trained_params.pkl', map_location=device))\n",
    "        \n",
    "        # generate and save config json file                                         \n",
    "        config = graph_network.create_config().to_json_best_effort()\n",
    "        with open(foldername+'/config.json', 'w') as f:\n",
    "            json.dump(config, f)\n",
    "        \n",
    "        print(f'Created {gnn} config.json and saved to {foldername}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from config example\n",
    "config = f'/scratch/datasets/retro_branching/supervised_learner/gnn/{gnn}/checkpoint_{cp}/config.json'\n",
    "print(config)\n",
    "loaded_graph_network = BipartiteGCN(device=device, config=config)\n",
    "loaded_graph_network.load_state_dict(torch.load(f'/scratch/datasets/retro_branching/supervised_learner/gnn/{gnn}/checkpoint_{cp}/trained_params.pkl', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rl_gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_networks = {f'rl_gnn_{i}': {'filter_network': None, # None 'gnn_235\n",
    "                                   'filter_method': 'method_2',\n",
    "                                   'checkpoints': 'all', # np.arange(1, 225, 25)\n",
    "                                   'emb_size': 64,\n",
    "                                   'num_rounds': 1,\n",
    "                                   'cons_nfeats': 5,\n",
    "                                   'edge_nfeats': 1,\n",
    "                                   'var_nfeats': 19, # 20 (if filter_network is not None) 19\n",
    "                                   'aggregator': 'add'} for i in [578]}\n",
    "\n",
    "filter_networks = {f'gnn_{i}': {'checkpoint': cp,\n",
    "                                'emb_size': 128,\n",
    "                                'num_rounds': 2,\n",
    "                                'cons_nfeats': 5,\n",
    "                                'edge_nfeats': 1,\n",
    "                                'var_nfeats': 19,\n",
    "                                'aggregator': 'add'} for i, cp in zip([261], [58])}\n",
    "\n",
    "for rl_gnn in policy_networks.keys():\n",
    "    if policy_networks[rl_gnn]['checkpoints'] == 'all':\n",
    "        # load all checkpoints\n",
    "        path = f'/scratch/datasets/retro_branching/reinforce_learner/rl_gnn/{rl_gnn}/'\n",
    "        policy_networks[rl_gnn]['checkpoints'] = [int(p.split('/')[-1].split('_')[-1]) for p in glob.glob(path+'checkpoint_*')]\n",
    "    \n",
    "    for cp in policy_networks[rl_gnn]['checkpoints']:\n",
    "        # load gnn from state dict\n",
    "        foldername = path + f'/checkpoint_{cp}'\n",
    "        \n",
    "        # load policy network\n",
    "        policy_network = BipartiteGCN(device,\n",
    "                                    emb_size=policy_networks[rl_gnn]['emb_size'],\n",
    "                                    num_rounds=policy_networks[rl_gnn]['num_rounds'],\n",
    "                                    cons_nfeats=policy_networks[rl_gnn]['cons_nfeats'],\n",
    "                                    edge_nfeats=policy_networks[rl_gnn]['edge_nfeats'],\n",
    "                                    var_nfeats=policy_networks[rl_gnn]['var_nfeats'],\n",
    "                                    aggregator=policy_networks[rl_gnn]['aggregator'])\n",
    "        policy_network.load_state_dict(torch.load(f'/scratch/datasets/retro_branching/reinforce_learner/rl_gnn/{rl_gnn}/checkpoint_{cp}/trained_params.pkl', map_location=device))\n",
    "    \n",
    "        # load filter network (if applicable)\n",
    "        if policy_networks[rl_gnn]['filter_network'] is not None:\n",
    "            # init filter network\n",
    "            filter_name = policy_networks[rl_gnn]['filter_network']\n",
    "            filter_network = BipartiteGCN(device,\n",
    "                                    emb_size=filter_networks[filter_name]['emb_size'],\n",
    "                                    num_rounds=filter_networks[filter_name]['num_rounds'],\n",
    "                                    cons_nfeats=filter_networks[filter_name]['cons_nfeats'],\n",
    "                                    edge_nfeats=filter_networks[filter_name]['edge_nfeats'],\n",
    "                                    var_nfeats=filter_networks[filter_name]['var_nfeats'],\n",
    "                                    aggregator=filter_networks[filter_name]['aggregator'])\n",
    "            filter_network.load_state_dict(torch.load('/scratch/datasets/retro_branching/supervised_learner/gnn/{}/checkpoint_{}/trained_params.pkl'.format(filter_name, filter_networks[filter_name]['checkpoint']), map_location=device))\n",
    "            \n",
    "            # save filter network state in same dir as where config will be saved\n",
    "            filename = foldername+'/filter_params.pkl'\n",
    "            torch.save(filter_network.state_dict(), filename)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            filter_network = None\n",
    "        \n",
    "        # init agent\n",
    "        agent = REINFORCEAgent(policy_network=policy_network, filter_network=filter_network, device=device, name=rl_gnn, filter_method=policy_networks[rl_gnn]['filter_method'])\n",
    "        \n",
    "        # generate and save config json file                                         \n",
    "        config = agent.create_config().to_json_best_effort()\n",
    "        with open(foldername+'/config.json', 'w') as f:\n",
    "            json.dump(config, f)\n",
    "        \n",
    "        print(f'Created {rl_gnn} config.json and saved to {foldername}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from config example\n",
    "config = f'/scratch/datasets/retro_branching/reinforce_learner/rl_gnn/{rl_gnn}/checkpoint_{cp}/config.json'\n",
    "print(config)\n",
    "loaded_agent = REINFORCEAgent(device=device, config=config)\n",
    "loaded_agent.policy_network.load_state_dict(torch.load(f'/scratch/datasets/retro_branching/reinforce_learner/rl_gnn/{rl_gnn}/checkpoint_{cp}/trained_params.pkl', map_location=device))\n",
    "if loaded_agent.filter_network is not None:\n",
    "    loaded_agent.filter_network.load_state_dict(torch.load(f'/scratch/datasets/retro_branching/reinforce_learner/rl_gnn/{rl_gnn}/checkpoint_{cp}/filter_params.pkl', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlgnn",
   "language": "python",
   "name": "rlgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
