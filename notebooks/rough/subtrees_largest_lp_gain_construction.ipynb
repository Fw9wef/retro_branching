{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each branching decision, choose child with largest LP gain as next step. This should enable agent to learn to predict which states it should see next and therefore have a better chance of predicting episode length and long-term return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from retro_branching.environments import EcoleBranching, EcoleConfiguring\n",
    "from retro_branching.agents import StrongBranchingAgent, PseudocostBranchingAgent, RandomAgent\n",
    "from retro_branching.utils import seed_stochastic_modules_globally\n",
    "# from retro_branching.rewards import NormalisedLPGain\n",
    "\n",
    "import ecole\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import pyscipopt\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms.shortest_paths.generic import shortest_path\n",
    "from networkx.algorithms.traversal.depth_first_search import dfs_tree\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "import matplotlib.pyplot as plt\n",
    "from ordered_set import OrderedSet\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "class SearchTree:\n",
    "    '''\n",
    "    Tracks SCIP search tree. Call SearchTree.update_tree(ecole.Model) each\n",
    "    time the ecole environments (and therefore the ecole.Model) is updated.\n",
    "\n",
    "    N.B. SCIP does not store nodes which were pruned, infeasible, outside\n",
    "    the search tree's optimality bounds, or which node was optimal, therefore these nodes will not be\n",
    "    stored in the SearchTree. This is why m.getNTotalNodes() (the total number\n",
    "    of nodes processed by SCIP) will likely be more than the number of nodes in\n",
    "    the search tree when an instance is solved.\n",
    "    '''\n",
    "    def __init__(self, model):        \n",
    "        self.tree = nx.DiGraph()\n",
    "        \n",
    "        self.tree.graph['root_node'] = None\n",
    "        self.tree.graph['visited_nodes'] = []\n",
    "        self.tree.graph['visited_node_ids'] = OrderedSet()\n",
    "        \n",
    "        self.tree.graph['optimum_node_id'] = None\n",
    "        self.init_primal_bound = model.as_pyscipopt().getPrimalbound()\n",
    "        self.tree.graph['incumbent_primal_bound'] = self.init_primal_bound\n",
    "        \n",
    "        self.prev_primal_bound = None\n",
    "        self.prev_node_id = None\n",
    "\n",
    "        self.step_idx = 0\n",
    "        \n",
    "        self.update_tree(model)\n",
    "            \n",
    "    def update_tree(self, model):\n",
    "        '''\n",
    "        Call this method after each update to the ecole environment. Pass\n",
    "        the updated ecole.Model, and the B&B tree tracker will be updated accordingly.\n",
    "        '''\n",
    "        m = model.as_pyscipopt()\n",
    "                \n",
    "        _curr_node = m.getCurrentNode()\n",
    "        if _curr_node is not None:\n",
    "            self.curr_node_id = _curr_node.getNumber()\n",
    "#             if len(self.tree.graph['optimum_node_ids']) == 0:\n",
    "#                 # not yet set, set as root node\n",
    "#                 self.tree.graph['optimum_node_ids'].append(self.curr_node_id)\n",
    "        else:\n",
    "            # branching finished, no curr node\n",
    "            self.curr_node_id = None\n",
    "            \n",
    "        if self.init_primal_bound == self.tree.graph['incumbent_primal_bound'] and self.curr_node_id is not None:\n",
    "            # not yet found better incumbent, set optimum node as current node\n",
    "            self.tree.graph['optimum_node_id'] = self.curr_node_id\n",
    "        \n",
    "        # check if previous branching at previous node changed global primal bound. If so, se previous node as optimum\n",
    "        if len(self.tree.graph['visited_node_ids']) >= 1:\n",
    "            self.prev_node_id = self.tree.graph['visited_node_ids'][-1]\n",
    "            if m.getPrimalbound() < self.tree.graph['incumbent_primal_bound']:\n",
    "                # branching at previous node led to finding new incumbent solution\n",
    "                self.tree.graph['optimum_node_id'] = self.prev_node_id\n",
    "                self.tree.graph['incumbent_primal_bound'] = m.getPrimalbound()\n",
    "            \n",
    "        self.curr_node = {self.curr_node_id: _curr_node}\n",
    "        if self.curr_node_id is not None:\n",
    "            if self.curr_node_id not in self.tree.graph['visited_node_ids']:\n",
    "                self._add_nodes(self.curr_node)\n",
    "                self.tree.graph['visited_nodes'].append(self.curr_node)\n",
    "                self.tree.graph['visited_node_ids'].add(self.curr_node_id)\n",
    "                self.tree.nodes[self.curr_node_id]['step_visited'] = self.step_idx\n",
    "        \n",
    "        if self.curr_node_id is not None:\n",
    "            _parent_node = list(self.curr_node.values())[0].getParent()\n",
    "            if _parent_node is not None:\n",
    "                parent_node_id = _parent_node.getNumber()\n",
    "            else:\n",
    "                # curr node is root node\n",
    "                parent_node_id = None\n",
    "            self.parent_node = {parent_node_id: _parent_node}\n",
    "        else:\n",
    "            self.parent_node = {None: None}\n",
    "            \n",
    "        open_leaves, open_children, open_siblings = m.getOpenNodes()\n",
    "        self.open_leaves = {node.getNumber(): node  for node in open_leaves}\n",
    "        self.open_children = {node.getNumber(): node for node in open_children}\n",
    "        self.open_siblings = {node.getNumber(): node for node in open_siblings}\n",
    "        \n",
    "        self._add_nodes(self.open_leaves)\n",
    "        self._add_nodes(self.open_children)\n",
    "        self._add_nodes(self.open_siblings)   \n",
    "\n",
    "        self.step_idx += 1\n",
    "\n",
    "                \n",
    "    def _add_nodes(self, nodes, parent_node_id=None):\n",
    "        '''Adds nodes if not already in tree.'''\n",
    "        for node_id, node in nodes.items():\n",
    "            if node_id not in self.tree:\n",
    "                # add node\n",
    "                self.tree.add_node(node_id,\n",
    "                                   _id=node_id,\n",
    "                                   lower_bound=node.getLowerbound())\n",
    "\n",
    "                # add edge\n",
    "                _parent_node = node.getParent()\n",
    "                if _parent_node is not None:\n",
    "                    if parent_node_id is None:\n",
    "                        parent_node_id = _parent_node.getNumber()\n",
    "                    else:\n",
    "                        # parent node id already given\n",
    "                        pass\n",
    "                    self.tree.add_edge(parent_node_id,\n",
    "                                       node_id)\n",
    "                else:\n",
    "                    # is root node, has no parent\n",
    "                    self.tree.graph['root_node'] = {node_id: node}\n",
    "                                    \n",
    "                \n",
    "    def render(self):\n",
    "        '''Renders B&B search tree.'''\n",
    "        fig = plt.figure()\n",
    "        \n",
    "        pos = graphviz_layout(self.tree, prog='dot')\n",
    "        node_labels = {node: node for node in self.tree.nodes}\n",
    "        nx.draw_networkx_nodes(self.tree,\n",
    "                               pos,\n",
    "                               label=node_labels)\n",
    "        nx.draw_networkx_edges(self.tree,\n",
    "                               pos)\n",
    "        \n",
    "        nx.draw_networkx_labels(self.tree, pos, labels=node_labels)\n",
    "        \n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalised LP Gain Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalisedLPGain:\n",
    "    def __init__(self, \n",
    "                 use_binary_sparse_rewards=False,\n",
    "                 normaliser='init_primal_bound', \n",
    "                 transform_with_log=False,\n",
    "                 epsilon=None):\n",
    "        '''\n",
    "        Args:\n",
    "            use_binary_sparse_rewards (bool): If True, rather than LP-gain, will simply\n",
    "                return a 1 on the step that solves the instance and a 0 on all\n",
    "                other steps. Implemented this here to save writing another class\n",
    "                which tracks sub-trees.\n",
    "            normaliser ('init_primal_bound', 'curr_primal_bound'): What to normalise\n",
    "                with respect to in the numerator and denominator to calculate\n",
    "                the per-step normalsed LP gain reward.\n",
    "            transform_with_log: If True, will transform the reward by doing\n",
    "                reward = sign(reward) * log(1 + |reward|) -> helps reduce variance\n",
    "                of reward as in https://arxiv.org/pdf/1704.03732.pdf\n",
    "            epsilon (None, float): If not None, will set score of nodes which\n",
    "                were pruned, infeasible, or outside of bounds to epsilon (rather than\n",
    "                0 if added or rather than not considering at all if never added to tree).\n",
    "                N.B. epsilon should be a small number e.g. 1e-6. N.B.2. Current\n",
    "                implementation assumes each branching decision results in 2 child\n",
    "                nodes (regardless of whether or not SCIP stores these in memory).\n",
    "        '''\n",
    "        self.use_binary_sparse_rewards = use_binary_sparse_rewards\n",
    "        self.normaliser = normaliser\n",
    "        self.transform_with_log = transform_with_log\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def before_reset(self, model):\n",
    "        self.prev_node = None\n",
    "        self.prev_node_id = None\n",
    "        self.prev_primal_bound = None\n",
    "        self.init_primal_bound = None\n",
    "\n",
    "    def extract(self, model, done):\n",
    "        m = model.as_pyscipopt()\n",
    "\n",
    "        if self.prev_node_id is None:\n",
    "            # not yet started, update prev node for next step\n",
    "            self.prev_node = m.getCurrentNode()\n",
    "            self.tree = SearchTree(model)\n",
    "            if self.prev_node is not None:\n",
    "                self.prev_node_id = copy.deepcopy(self.prev_node.getNumber())\n",
    "                self.prev_primal_bound = m.getPrimalbound()\n",
    "                self.init_primal_bound = m.getPrimalbound()\n",
    "            return 0\n",
    "\n",
    "        # update search tree with current model state\n",
    "        self.tree.update_tree(model)\n",
    "        \n",
    "        # collect node stats from children introduced from previous branching decision\n",
    "        prev_node_lb = self.tree.tree.nodes[self.prev_node_id]['lower_bound']\n",
    "        prev_node_child_ids = [child for child in self.tree.tree.successors(self.prev_node_id)]\n",
    "        prev_node_child_lbs = [self.tree.tree.nodes[child]['lower_bound'] for child in prev_node_child_ids]\n",
    "\n",
    "        # calc reward for previous branching decision\n",
    "        if len(prev_node_child_lbs) > 0:\n",
    "            # use child lp gains to retrospectively calculate a score for the previous branching decision\n",
    "            closed_by_agent = False\n",
    "            if self.use_binary_sparse_rewards:\n",
    "                # score = 0\n",
    "                score = -1\n",
    "            else:\n",
    "                score = -1\n",
    "                for child_node_lb in prev_node_child_lbs:\n",
    "                    if self.normaliser == 'curr_primal_bound':\n",
    "                        # use primal bound of step branching action was taken\n",
    "                        score *= (self.prev_primal_bound - child_node_lb) / (self.prev_primal_bound - prev_node_lb)\n",
    "                    elif self.normaliser == 'init_primal_bound':\n",
    "                        # use init primal bound\n",
    "                        score *= (self.init_primal_bound - child_node_lb) / (self.init_primal_bound - prev_node_lb)\n",
    "                    else:\n",
    "                        raise Exception(f'Unrecognised normaliser {self.normaliser}')\n",
    "                if self.epsilon is not None:\n",
    "                    # consider child nodes which were never added to search tree by SCIP\n",
    "                    for _ in range(int(2-len(prev_node_child_lbs))):\n",
    "                        score *= self.epsilon\n",
    "        else:\n",
    "            # previous branching decision led to all child nodes being pruned, infeasible, or outside bounds -> don't punish brancher\n",
    "            closed_by_agent = True\n",
    "            if self.use_binary_sparse_rewards:\n",
    "                # score = 1\n",
    "                score = 0\n",
    "            else:\n",
    "                if self.epsilon is not None:\n",
    "                    score = -1 * (self.epsilon**2)\n",
    "                else:\n",
    "                    score = 0\n",
    "\n",
    "        # update tree with effect(s) of branching decision\n",
    "        self.tree.tree.nodes[self.prev_node_id]['score'] = score\n",
    "        self.tree.tree.nodes[self.prev_node_id]['closed_by_agent'] = closed_by_agent\n",
    "\n",
    "        if m.getCurrentNode() is not None:\n",
    "            # update stats for next step\n",
    "            self.prev_node = m.getCurrentNode()\n",
    "            self.prev_node_id = copy.deepcopy(self.prev_node.getNumber())\n",
    "            self.prev_primal_bound = m.getPrimalbound()\n",
    "        else:\n",
    "            # instance completed, no current focus node\n",
    "            pass\n",
    "\n",
    "        if self.transform_with_log:\n",
    "            sign = math.copysign(1, score)\n",
    "            score = sign * math.log(1 + abs(score), 10)\n",
    "\n",
    "        if score < -1:\n",
    "            print('Score < -1 found.')\n",
    "            for node in self.tree.tree.nodes():\n",
    "                print(f'Node {node} lb: {self.tree.tree.nodes[node][\"lower_bound\"]}')\n",
    "            raise Exception()\n",
    "        \n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-tree Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetroBranching:\n",
    "    def __init__(self, \n",
    "                 force_include_optimal_trajectory=True,\n",
    "                 force_include_branching_fathomed_transitions=False,\n",
    "                 only_return_optimal_trajectory=False,\n",
    "                 only_use_leaves_closed_by_brancher_as_terminal_nodes=False,\n",
    "                 set_score_as_subtree_size=False,\n",
    "                 use_binary_sparse_rewards=False,\n",
    "                 normaliser='init_primal_bound', \n",
    "                 min_subtree_depth=1, \n",
    "                 retro_trajectory_construction='deepest',\n",
    "                 remove_nonoptimal_fathomed_leaves=False,\n",
    "                 use_mean_return_rooted_at_node=False,\n",
    "                 use_sum_return_rooted_at_node=False,\n",
    "                 transform_with_log=False,\n",
    "                 debug_mode=False):\n",
    "        '''\n",
    "        Waits until end of episode to calculate rewards for each step, then retrospectively\n",
    "        goes back through each step in the episode and calculates reward for that step.\n",
    "        I.e. reward returned will be None until the end of the episode, at which\n",
    "        point a dict mapping episode_step_idx for optimal path nodes to reward will be returned.\n",
    "\n",
    "        The terminal sub-tree will first retrospectively construct an episode from the root node\n",
    "        to the opimal node (i.e. the 'optimal path') and make this as one episode. Then, it will\n",
    "        iteratively go through all other nodes in the B&B tree not already included in a retrospective\n",
    "        sub-tree episode path and construct sub-trees randomly untill all nodes experiences by the agent\n",
    "        are included in an episode. Will then return a list, where each element in the list is a dict\n",
    "        mapping the step index in the original episode and the corresponding reward received by the agent.\n",
    "        \n",
    "        Args:\n",
    "            force_include_branching_fathomed_transitions (bool): If True, will include\n",
    "                a sub-tree episode if the final transition was a sub-tree closed by\n",
    "                the brancher even if they total episode length is < min_subtree_depth.\n",
    "            use_binary_sparse_rewards (bool): If True, rather than LP-gain, will simply\n",
    "                return a 1 on the step that solves the instance and a 0 on all\n",
    "                other steps. Implemented this here to save writing another class\n",
    "                which tracks sub-trees.\n",
    "            normaliser ('init_primal_bound', 'curr_primal_bound'): What to normalise\n",
    "                with respect to in the numerator and denominator to calculate\n",
    "                the per-step normalsed LP gain reward.\n",
    "            min_subtree_depth (int): Minimum depth of sub-tree (i.e. minimum length of sub-tree episode).\n",
    "            retro_trajectory_construction ('random', 'deepest', 'shortest', 'max_lp_gain', 'min_lp_gain', 'max_leaf_lp_gain', \n",
    "                'reverse_visitation_order'): Which policy to use when choosing a leaf node as the final \n",
    "                node to construct a sub-tree.\n",
    "            remove_nonoptimal_fathomed_leaves (bool): If True, at end of episode, will remove\n",
    "                all leaves in tree which were fathomed (had score == 0) except optimal path leaf \n",
    "                so that no non-optimal sub-tree will have been fathomed and contain a \n",
    "                node/experience with score == 0.\n",
    "            use_mean_return_rooted_at_node (bool): If True, for each step in a given\n",
    "                sub-tree episode, rather than just using the original step reward,\n",
    "                will:\n",
    "                    1) get the sub-tree rooted at the current node (step)\n",
    "                    2) get the paths from the sub-tree root to each of its leaves\n",
    "                    3) sum the reward across each of these paths to get a backprop'd return from the current node\n",
    "                    4) divide this by the number of these paths to get the mean backprop'd return from the current node\n",
    "\n",
    "        '''\n",
    "        if use_mean_return_rooted_at_node and use_sum_return_rooted_at_node:\n",
    "            raise Exception('use_mean_return_rooted_at_node and use_sum_return_rooted_at_node cannot both be True.')\n",
    "\n",
    "        self.force_include_optimal_trajectory = force_include_optimal_trajectory\n",
    "        self.force_include_branching_fathomed_transitions = force_include_branching_fathomed_transitions\n",
    "        self.only_return_optimal_trajectory = only_return_optimal_trajectory\n",
    "        self.only_use_leaves_closed_by_brancher_as_terminal_nodes = only_use_leaves_closed_by_brancher_as_terminal_nodes\n",
    "        if not force_include_optimal_trajectory and only_return_optimal_trajectory:\n",
    "            raise Exception('Must force inclusion of optimal sub-tree if only want to return optimal sub-tree.')\n",
    "        self.set_score_as_subtree_size = set_score_as_subtree_size\n",
    "        self.use_binary_sparse_rewards = use_binary_sparse_rewards\n",
    "        self.min_subtree_depth = min_subtree_depth\n",
    "        self.retro_trajectory_construction = retro_trajectory_construction\n",
    "        self.normalised_lp_gain = NormalisedLPGain(use_binary_sparse_rewards=use_binary_sparse_rewards, \n",
    "                                                   normaliser=normaliser) # normalised lp gain reward tracker\n",
    "        self.remove_nonoptimal_fathomed_leaves = remove_nonoptimal_fathomed_leaves\n",
    "        self.use_mean_return_rooted_at_node = use_mean_return_rooted_at_node\n",
    "        self.use_sum_return_rooted_at_node = use_sum_return_rooted_at_node\n",
    "        self.transform_with_log = transform_with_log\n",
    "        self.debug_mode = debug_mode\n",
    "\n",
    "    def before_reset(self, model):\n",
    "        self.started = False\n",
    "        self.normalised_lp_gain.before_reset(model)\n",
    "        \n",
    "    def get_path_node_scores(self, tree, path):\n",
    "        if self.use_mean_return_rooted_at_node or self.use_sum_return_rooted_at_node:\n",
    "            scores = []\n",
    "            # use mean return from node across all paths as score for each node\n",
    "            for root_node in path:\n",
    "                # get sub-tree rooted from this node\n",
    "                subtree = dfs_tree(tree, root_node)\n",
    "\n",
    "                # get leaf nodes of sub-tree\n",
    "                leaf_nodes = [n for n in subtree.nodes() if subtree.out_degree(n) == 0]\n",
    "\n",
    "                # get paths in sub-tree\n",
    "                subtree_paths = [shortest_path(subtree, source=root_node, target=leaf_node) for leaf_node in leaf_nodes]\n",
    "\n",
    "                # get total reward across all paths\n",
    "                R = 0\n",
    "                for p in subtree_paths:\n",
    "                    for n in p:\n",
    "                        R += tree.nodes[n]['score']\n",
    "\n",
    "                if self.use_mean_return_rooted_at_node:\n",
    "                    # get mean return across all paths from current node -> use as node score\n",
    "                    R /= len(subtree_paths)\n",
    "                elif self.use_sum_return_rooted_at_node:\n",
    "                    # already summed\n",
    "                    pass\n",
    "                else:\n",
    "                    raise Exception('Not implemented.')\n",
    "\n",
    "                scores.append(R)\n",
    "\n",
    "        else:\n",
    "            # use original node score as score for each node\n",
    "            scores = [tree.nodes[node]['score'] for node in path]\n",
    "\n",
    "        if self.transform_with_log:\n",
    "            for idx, score in enumerate(scores):\n",
    "                sign = math.copysign(1, score)\n",
    "                score = sign * math.log(1 + abs(score), 10)\n",
    "                scores[idx] = score\n",
    "\n",
    "        return scores\n",
    "\n",
    "\n",
    "        \n",
    "    def conv_path_to_step_idx_reward_map(self, path, check_depth=True):        \n",
    "        # register which nodes have been directly included in the sub-tree\n",
    "        for node in path:\n",
    "            self.nodes_added.add(node)\n",
    "            \n",
    "        if check_depth:\n",
    "            if len(path) < self.min_subtree_depth:\n",
    "                # subtree not deep enough, do not use episode (but count all nodes as having been added)\n",
    "                if self.force_include_branching_fathomed_transitions:\n",
    "                    if self.normalised_lp_gain.tree.tree.nodes[path[-1]]['score'] == 0:\n",
    "                        # brancher fathomed sub-tree, should include sub-tree even though is less than min_subtree_depth\n",
    "                        pass\n",
    "                    else:\n",
    "                        # brancher did not fathom sub-tree and is less than min_subtree_depth, do not use\n",
    "                        return None\n",
    "                else:\n",
    "                    # sub-tree is less than min_subtree_depth, do not use\n",
    "                    return None\n",
    "        \n",
    "        # get rewards at each step in sub-tree episode\n",
    "        path_node_rewards = self.get_path_node_scores(self.normalised_lp_gain.tree.tree, path)\n",
    "\n",
    "        # get episode step indices at which each node in sub-tree was visited\n",
    "        path_to_step_idx = {node: self.visited_nodes_to_step_idx[node] for node in path}\n",
    "\n",
    "        # map each path node episode step idx to its corresponding reward\n",
    "        step_idx_to_reward = {step_idx: r for step_idx, r in zip(list(path_to_step_idx.values()), path_node_rewards)}\n",
    "        \n",
    "        return step_idx_to_reward\n",
    "\n",
    "    def _select_path_in_subtree(self, subtree):\n",
    "        for root_node in subtree.nodes:\n",
    "            if subtree.in_degree(root_node) == 0:\n",
    "                # node is root\n",
    "                break\n",
    "\n",
    "        # use a construction method to select a sub-tree episode path through the sub-tree\n",
    "        if self.retro_trajectory_construction == 'max_lp_gain' or self.retro_trajectory_construction == 'min_lp_gain':\n",
    "            if self.only_use_leaves_closed_by_brancher_as_terminal_nodes:\n",
    "                raise Exception('Have not implemented only_use_leaves_closed_by_brancher_as_terminal_nodes for this subtree construction method.')\n",
    "            # iteratively decide next node in path at each step\n",
    "            curr_node, path = root_node, [root_node]\n",
    "            while True:\n",
    "                # get potential next node(s)\n",
    "                children = [child for child in subtree.successors(curr_node)]\n",
    "                if len(children) == 0:\n",
    "                    # curr node is final leaf node, path complete\n",
    "                    break\n",
    "                else:\n",
    "                    # select next node\n",
    "                    if self.retro_trajectory_construction == 'max_lp_gain':\n",
    "                        idx = np.argmax([subtree.nodes[child]['lower_bound'] for child in children])\n",
    "                    elif self.retro_trajectory_construction == 'min_lp_gain':\n",
    "                        idx = np.argmin([subtree.nodes[child]['lower_bound'] for child in children])\n",
    "                    else:\n",
    "                        raise Exception(f'Unrecognised retro_trajectory_construction {self.retro_trajectory_construction}')\n",
    "                    curr_node = children[idx]\n",
    "                    path.append(curr_node)\n",
    "                \n",
    "        else:\n",
    "            # first get leaf nodes and then use construction method to select leaf target for shortest path\n",
    "            if self.only_use_leaves_closed_by_brancher_as_terminal_nodes:\n",
    "                leaf_nodes = [node for node in subtree.nodes() if (subtree.out_degree(node) == 0 and subtree.nodes[node]['score'] == 0)]\n",
    "            else:\n",
    "                leaf_nodes = [node for node in subtree.nodes() if subtree.out_degree(node) == 0]\n",
    "            \n",
    "            if len(leaf_nodes) == 0:\n",
    "                # could not find any valid path through sub-tree\n",
    "                return []\n",
    "\n",
    "            if self.retro_trajectory_construction == 'random':\n",
    "                # randomly choose leaf node as final node\n",
    "                final_node = leaf_nodes[random.choice(range(len(leaf_nodes)))]\n",
    "            elif self.retro_trajectory_construction == 'deepest':\n",
    "                # choose leaf node which would lead to deepest subtree as final node\n",
    "                depths = [len(shortest_path(subtree, source=root_node, target=leaf_node)) for leaf_node in leaf_nodes]\n",
    "                final_node = leaf_nodes[depths.index(max(depths))]\n",
    "            elif self.retro_trajectory_construction == 'shortest':\n",
    "                # choose leaf node which would lead to shortest subtree as final node\n",
    "                depths = [len(shortest_path(subtree, source=root_node, target=leaf_node)) for leaf_node in leaf_nodes]\n",
    "                final_node = leaf_nodes[depths.index(min(depths))]\n",
    "            elif self.retro_trajectory_construction == 'max_leaf_lp_gain':\n",
    "                # choose leaf node which has greatest LP gain as final node\n",
    "                lp_gains = [subtree.nodes[leaf_node]['lower_bound'] for leaf_node in leaf_nodes]\n",
    "                final_node = leaf_nodes[lp_gains.index(max(lp_gains))]\n",
    "            elif self.retro_trajectory_construction == 'reverse_visitation_order':\n",
    "                step_node_visited = [self.normalised_lp_gain.tree.tree.nodes[leaf_node]['step_visited'] for leaf_node in leaf_nodes]\n",
    "                final_node = leaf_nodes[step_node_visited.index(max(step_node_visited))]\n",
    "            else:\n",
    "                raise Exception(f'Unrecognised retro_trajectory_construction {self.retro_trajectory_construction}')\n",
    "            path = shortest_path(self.normalised_lp_gain.tree.tree, source=root_node, target=final_node)\n",
    "\n",
    "        return path\n",
    "\n",
    "    def extract(self, model, done):\n",
    "        # update normalised LP gain tracker\n",
    "        _ = self.normalised_lp_gain.extract(model, done)\n",
    "\n",
    "        if not done:\n",
    "            return None\n",
    "        else:\n",
    "            # instance finished, retrospectively create subtree episode paths\n",
    "\n",
    "            if self.normalised_lp_gain.tree.tree.graph['root_node'] is None:\n",
    "                # instance was pre-solved\n",
    "                # if self.use_binary_sparse_rewards:\n",
    "                    # return [{0: -1}]\n",
    "                # else:\n",
    "                    # return [{0: 0}]\n",
    "                return [{0: 0}]\n",
    "\n",
    "            # collect sub-tree episodes\n",
    "            subtrees_step_idx_to_reward = []\n",
    "\n",
    "            # keep track of which nodes have been added to a sub-tree\n",
    "            self.nodes_added = set()\n",
    "            \n",
    "            if self.debug_mode:\n",
    "                print('\\nB&B tree:')\n",
    "                print(f'All nodes saved: {self.normalised_lp_gain.tree.tree.nodes()}')\n",
    "                print(f'Visited nodes: {self.normalised_lp_gain.tree.tree.graph[\"visited_node_ids\"]}')\n",
    "                self.normalised_lp_gain.tree.render()\n",
    "\n",
    "            # remove nodes which were never visited by the brancher and therefore do not have a score or next state\n",
    "            nodes = [node for node in self.normalised_lp_gain.tree.tree.nodes]\n",
    "            for node in nodes:\n",
    "                if 'score' not in self.normalised_lp_gain.tree.tree.nodes[node]:\n",
    "                    self.normalised_lp_gain.tree.tree.remove_node(node)\n",
    "                    if node in self.normalised_lp_gain.tree.tree.graph['visited_node_ids']:\n",
    "                        # hack: SCIP sometimes returns large int rather than None node_id when episode finished\n",
    "                        # since never visited this node (since no score assigned), do not count this node as having been visited when calculating paths below\n",
    "                        if self.debug_mode:\n",
    "                            print(f'Removing node {node} since was never visited by brancher.')\n",
    "                        self.normalised_lp_gain.tree.tree.graph['visited_node_ids'].remove(node)\n",
    "                        \n",
    "            if self.only_use_leaves_closed_by_brancher_as_terminal_nodes:\n",
    "                # remove leaf nodes which were never fathomed by brancher\n",
    "                nodes = [node for node in self.normalised_lp_gain.tree.tree.nodes]\n",
    "                for node in nodes:\n",
    "                    if self.normalised_lp_gain.tree.tree.out_degree(node) == 0 and self.normalised_lp_gain.tree.tree.nodes[node]['score'] != 0:\n",
    "                        self.normalised_lp_gain.tree.tree.remove_node(node)\n",
    "                        if node in self.normalised_lp_gain.tree.tree.graph['visited_node_ids']:\n",
    "                            if self.debug_mode:\n",
    "                                print(f'Removing leaf node {node} since was never fathomed by brancher.')\n",
    "                            self.normalised_lp_gain.tree.tree.graph['visited_node_ids'].remove(node)\n",
    "\n",
    "            # map which nodes were visited at which step in episode\n",
    "            self.visited_nodes_to_step_idx = {node: idx for idx, node in enumerate(self.normalised_lp_gain.tree.tree.graph['visited_node_ids'])}\n",
    "\n",
    "            if self.set_score_as_subtree_size:\n",
    "                for node in self.normalised_lp_gain.tree.tree.nodes():\n",
    "                    # get sub-tree rooted at node\n",
    "                    subtree = dfs_tree(self.normalised_lp_gain.tree.tree, node)\n",
    "                    \n",
    "                    # set node score as negative length of sub-tree beneath it (not including root node)\n",
    "                    self.normalised_lp_gain.tree.tree.nodes[node]['score'] = -(len(subtree) - 1)\n",
    "            \n",
    "            root_node = list(self.normalised_lp_gain.tree.tree.graph['root_node'].keys())[0]\n",
    "            if self.force_include_optimal_trajectory:\n",
    "                # get optimal path\n",
    "                final_node = self.normalised_lp_gain.tree.tree.graph['optimum_node_id']\n",
    "                path = shortest_path(self.normalised_lp_gain.tree.tree, source=root_node, target=final_node)\n",
    "                subtrees_step_idx_to_reward.append(self.conv_path_to_step_idx_reward_map(path, check_depth=False))\n",
    "\n",
    "                if self.only_return_optimal_trajectory:\n",
    "                    return subtrees_step_idx_to_reward\n",
    "\n",
    "                if self.remove_nonoptimal_fathomed_leaves:\n",
    "                    for node in nodes:\n",
    "                        if node in self.normalised_lp_gain.tree.tree.nodes.keys():\n",
    "                            if self.normalised_lp_gain.tree.tree.nodes[node]['score'] == 0 and node != final_node:\n",
    "                                # node fathomed and not in optimal path, remove\n",
    "                                self.normalised_lp_gain.tree.tree.remove_node(node)\n",
    "                                if self.debug_mode:\n",
    "                                    print(f'Removed non-optimal fathomed leaf node {node}')\n",
    "            \n",
    "            # create sub-tree episodes from remaining B&B nodes visited by agent\n",
    "            while True:\n",
    "                # create depth first search sub-trees from nodes still leftover\n",
    "                nx_subtrees = []\n",
    "                \n",
    "                # construct sub-trees containing prospective sub-tree episode(s) from remaining nodes\n",
    "                if len(self.nodes_added) > 0:\n",
    "                    for node in self.nodes_added:\n",
    "                        children = [child for child in self.normalised_lp_gain.tree.tree.successors(node)]\n",
    "                        for child in children:\n",
    "                            if child not in self.nodes_added:\n",
    "                                nx_subtrees.append(dfs_tree(self.normalised_lp_gain.tree.tree, child))\n",
    "                else:\n",
    "                    # not yet added any nodes to a sub-tree, whole B&B tree is first 'sub-tree'\n",
    "                    nx_subtrees.append(dfs_tree(self.normalised_lp_gain.tree.tree, root_node))\n",
    "                            \n",
    "                for i, subtree in enumerate(nx_subtrees):\n",
    "                    # init node attributes for nodes in subtree (since these are not transferred into new subtree by networkx)\n",
    "                    for node in subtree.nodes:\n",
    "                        subtree.nodes[node]['score'] = self.normalised_lp_gain.tree.tree.nodes[node]['score']\n",
    "                        subtree.nodes[node]['lower_bound'] = self.normalised_lp_gain.tree.tree.nodes[node]['lower_bound']\n",
    "\n",
    "                    # choose episode path through sub-tree\n",
    "                    path = self._select_path_in_subtree(subtree)\n",
    "                    \n",
    "                    if len(path) > 0:\n",
    "                        # gather rewards in sub-tree\n",
    "                        subtree_step_idx_to_reward = self.conv_path_to_step_idx_reward_map(path, check_depth=True)\n",
    "                        if subtree_step_idx_to_reward is not None:\n",
    "                            subtrees_step_idx_to_reward.append(subtree_step_idx_to_reward)\n",
    "                        else:\n",
    "                            # subtree was not deep enough to be added\n",
    "                            pass\n",
    "                    else:\n",
    "                        # cannot establish valid path through sub-tree, do not consider nodes in this sub-tree again\n",
    "                        for node in subtree.nodes():\n",
    "                            self.nodes_added.add(node)\n",
    "\n",
    "                if len(nx_subtrees) == 0:\n",
    "                    # all sub-trees added\n",
    "                    break\n",
    "                    \n",
    "            if self.debug_mode:\n",
    "                print(f'visited_nodes_to_step_idx: {self.visited_nodes_to_step_idx}')\n",
    "                step_idx_to_visited_nodes = {val: key for key, val in self.visited_nodes_to_step_idx.items()}\n",
    "                print(f'step_idx_to_visited_nodes: {step_idx_to_visited_nodes}')\n",
    "                for i, ep in enumerate(subtrees_step_idx_to_reward):\n",
    "                    print(f'>>> sub-tree episode {i+1}: {ep}')\n",
    "                    ep_path = [step_idx_to_visited_nodes[idx] for idx in ep.keys()]\n",
    "                    print(f'path: {ep_path}')\n",
    "                    ep_dual_bounds = [self.normalised_lp_gain.tree.tree.nodes[node]['lower_bound'] for node in ep_path]\n",
    "                    print(f'ep_dual_bounds: {ep_dual_bounds}')\n",
    "            \n",
    "            if len(subtrees_step_idx_to_reward) == 0:\n",
    "                # solved at root so path length < min path length so was never added to subtrees\n",
    "                return [{0: 0}]\n",
    "            else:\n",
    "                return subtrees_step_idx_to_reward\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "seed = 1 # 1\n",
    "seed_stochastic_modules_globally(default_seed=seed)\n",
    "\n",
    "agent = PseudocostBranchingAgent()\n",
    "\n",
    "env = EcoleBranching(observation_function='default',\n",
    "                      information_function='default',\n",
    "                      reward_function='default',\n",
    "                      scip_params='default')\n",
    "env.seed(seed)\n",
    "\n",
    "ecole.seed(seed)\n",
    "instances = ecole.instance.SetCoverGenerator(n_rows=200, n_cols=200, density=0.05) # 200x200seed=1 300x300seed=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "custom_reward = RetroBranching(only_return_optimal_trajectory=False,\n",
    "                                         force_include_optimal_trajectory=False,\n",
    "                                         force_include_branching_fathomed_transitions=True,\n",
    "                                         only_use_leaves_closed_by_brancher_as_terminal_nodes=True,\n",
    "                                         set_score_as_subtree_size=True,\n",
    "                                         use_binary_sparse_rewards=True,\n",
    "                                         normaliser='init_primal_bound', \n",
    "                                         min_subtree_depth=1, \n",
    "                                         retro_trajectory_construction='shortest', # max_leaf_lp_gain\n",
    "                                         remove_nonoptimal_fathomed_leaves=False,\n",
    "                                         transform_with_log=True,\n",
    "                                         debug_mode=True)\n",
    "done = True\n",
    "while done:\n",
    "    env.seed(seed)\n",
    "    instance = next(instances)\n",
    "    custom_reward.before_reset(instance)\n",
    "    agent.before_reset(instance)\n",
    "    obs, action_set, reward, done, info = env.reset(instance)\n",
    "    _custom_reward = custom_reward.extract(env.model, done)\n",
    "    \n",
    "t = 0\n",
    "instance_transitions = []\n",
    "prev_obs = copy.deepcopy(obs)\n",
    "tree = custom_reward.normalised_lp_gain.tree\n",
    "while not done:\n",
    "    # select branching action\n",
    "    action, action_idx = agent.action_select(action_set, model=env.model, done=done)\n",
    "    obs, action_set, reward, done, info = env.step(action)\n",
    "    _custom_reward = custom_reward.extract(env.model, done)\n",
    "    \n",
    "    if done:\n",
    "        obs = copy.deepcopy(prev_obs)\n",
    "    \n",
    "    # store transition\n",
    "    instance_transitions.append({'obs': prev_obs,\n",
    "                               'action': action,\n",
    "#                                'reward': reward['normalised_lp_gain'],\n",
    "                               'reward': reward['num_nodes'],\n",
    "                               'done': done,\n",
    "                               'next_obs': obs})\n",
    "    \n",
    "    # update prev obs\n",
    "    prev_obs = copy.deepcopy(obs)\n",
    "    \n",
    "    m = env.model.as_pyscipopt()\n",
    "    if len(tree.tree.graph['visited_node_ids']) > 1 and not done:\n",
    "        prev_node_id = tree.tree.graph['visited_node_ids'][-2]\n",
    "    else:\n",
    "        prev_node_id = tree.tree.graph['visited_node_ids'][-1]\n",
    "    curr_node_id = tree.curr_node_id\n",
    "    print(f'Step {t} | Nodes added: {reward[\"num_nodes\"]:.3f} | primal bound: {m.getPrimalbound()} | dual bound: {m.getDualbound()} | prev_node_id (branched at): {prev_node_id} | next_node_id (not yet branched at): {curr_node_id} | optimum_node_id: {tree.tree.graph[\"optimum_node_id\"]}')\n",
    "    print(f'Custom reward: {_custom_reward}')\n",
    "    \n",
    "    # update search tree and analyse branching action\n",
    "    tree.update_tree(env.model)\n",
    "#     tree.render()\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    t += 1\n",
    "        \n",
    "m = env.model.as_pyscipopt()\n",
    "print(f'\\nFinished | primal bound: {m.getPrimalbound()} | dual bound: {m.getDualbound()} | # nodes: {m.getNTotalNodes()} | Final node: {tree.tree.graph[\"visited_nodes\"][-1]} | Optimum node id: {tree.tree.graph[\"optimum_node_id\"]}')\n",
    "print(f'Custom reward: {_custom_reward}')\n",
    "tree.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlgnn",
   "language": "python",
   "name": "rlgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
