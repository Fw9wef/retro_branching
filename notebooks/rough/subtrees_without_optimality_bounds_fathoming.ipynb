{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtrees without optimality bounds fathoming\n",
    "\n",
    "In B&B, can fathom sub-trees in 1 of 4 ways:\n",
    "\n",
    "1. **Optimality bounds**: Node's dual worse than global incumbent's primal -> no feasible solution better than incumbent can exist within the sub-tree \n",
    "\n",
    "2. **Infeasibility**: No dual solution which meets MILP's non-integrality constraints exists \n",
    "\n",
    "3. **Integrality**: Dual bound solution is feasible w.r.t. integrality constraints -> no better feasible solution can exist within sub-tree \n",
    "\n",
    "4. **Completion**: global_primal_dual_gap = 0 -> solution is optimal \n",
    "    \n",
    "Optimality bounds fathoming is dependent on the global incumbent. Therefore, we do not want a local sub-tree episode to be terminated due to activity which went on somewhere else in the tree, since we don't want our agent to concern itself with this.\n",
    "\n",
    "Can we work this into our reward and/or sub-tree episode construction procedure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from retro_branching.environments import EcoleBranching, EcoleConfiguring\n",
    "from retro_branching.agents import StrongBranchingAgent, PseudocostBranchingAgent, RandomAgent\n",
    "from retro_branching.utils import seed_stochastic_modules_globally\n",
    "# from retro_branching.rewards import NormalisedLPGain\n",
    "\n",
    "import ecole\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import pyscipopt\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms.shortest_paths.generic import shortest_path\n",
    "from networkx.algorithms.traversal.depth_first_search import dfs_tree\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "import matplotlib.pyplot as plt\n",
    "from ordered_set import OrderedSet\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "class SearchTree:\n",
    "    '''\n",
    "    Tracks SCIP search tree. Call SearchTree.update_tree(ecole.Model) each\n",
    "    time the ecole environments (and therefore the ecole.Model) is updated.\n",
    "\n",
    "    N.B. SCIP does not store nodes which were pruned, infeasible, outside\n",
    "    the search tree's optimality bounds, or which node was optimal, therefore these nodes will not be\n",
    "    stored in the SearchTree. This is why m.getNTotalNodes() (the total number\n",
    "    of nodes processed by SCIP) will likely be more than the number of nodes in\n",
    "    the search tree when an instance is solved.\n",
    "    '''\n",
    "    def __init__(self, model):        \n",
    "        self.tree = nx.DiGraph()\n",
    "        \n",
    "        self.tree.graph['root_node'] = None\n",
    "        self.tree.graph['visited_nodes'] = []\n",
    "        self.tree.graph['visited_node_ids'] = OrderedSet()\n",
    "        \n",
    "        self.update_tree(model)\n",
    "    \n",
    "    def update_tree(self, model):\n",
    "        '''\n",
    "        Call this method after each update to the ecole environments. Pass\n",
    "        the updated ecole.Model, and the B&B tree tracker will be updated accordingly.\n",
    "        '''\n",
    "        m = model.as_pyscipopt()\n",
    "        \n",
    "        _curr_node = m.getCurrentNode()\n",
    "        if _curr_node is not None:\n",
    "            curr_node_id = _curr_node.getNumber()\n",
    "        else:\n",
    "            # branching finished, no curr node\n",
    "            curr_node_id = None\n",
    "        self.curr_node = {curr_node_id: _curr_node}\n",
    "        if curr_node_id is not None:\n",
    "            if curr_node_id not in self.tree.graph['visited_node_ids']:\n",
    "                self._add_nodes(self.curr_node)\n",
    "                self.tree.graph['visited_nodes'].append(self.curr_node)\n",
    "                self.tree.graph['visited_node_ids'].add(curr_node_id)\n",
    "        \n",
    "        if curr_node_id is not None:\n",
    "            _parent_node = list(self.curr_node.values())[0].getParent()\n",
    "            if _parent_node is not None:\n",
    "                parent_node_id = _parent_node.getNumber()\n",
    "            else:\n",
    "                # curr node is root node\n",
    "                parent_node_id = None\n",
    "            self.parent_node = {parent_node_id: _parent_node}\n",
    "        else:\n",
    "            self.parent_node = {None: None}\n",
    "            \n",
    "        open_leaves, open_children, open_siblings = m.getOpenNodes()\n",
    "        self.open_leaves = {node.getNumber(): node  for node in open_leaves}\n",
    "        self.open_children = {node.getNumber(): node for node in open_children}\n",
    "        self.open_siblings = {node.getNumber(): node for node in open_siblings}\n",
    "        \n",
    "        self._add_nodes(self.open_leaves)\n",
    "        self._add_nodes(self.open_children)\n",
    "        self._add_nodes(self.open_siblings)\n",
    "                \n",
    "    def _add_nodes(self, nodes, parent_node_id=None):\n",
    "        '''Adds nodes if not already in tree.'''\n",
    "        for node_id, node in nodes.items():\n",
    "            if node_id not in self.tree:\n",
    "                # add node\n",
    "                self.tree.add_node(node_id,\n",
    "                                   _id=node_id,\n",
    "                                   lower_bound=node.getLowerbound())\n",
    "\n",
    "                # add edge\n",
    "                _parent_node = node.getParent()\n",
    "                if _parent_node is not None:\n",
    "                    if parent_node_id is None:\n",
    "                        parent_node_id = _parent_node.getNumber()\n",
    "                    else:\n",
    "                        # parent node id already given\n",
    "                        pass\n",
    "                    self.tree.add_edge(parent_node_id,\n",
    "                                       node_id)\n",
    "                else:\n",
    "                    # is root node, has no parent\n",
    "                    self.tree.graph['root_node'] = {node_id: node}\n",
    "                \n",
    "    def render(self):\n",
    "        '''Renders B&B search tree.'''\n",
    "        fig = plt.figure()\n",
    "        \n",
    "        pos = graphviz_layout(self.tree, prog='dot')\n",
    "        node_labels = {node: node for node in self.tree.nodes}\n",
    "        nx.draw_networkx_nodes(self.tree,\n",
    "                               pos,\n",
    "                               label=node_labels)\n",
    "        nx.draw_networkx_edges(self.tree,\n",
    "                               pos)\n",
    "        \n",
    "        nx.draw_networkx_labels(self.tree, pos, labels=node_labels)\n",
    "        \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalised LP Gain Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "class NormalisedLPGain:\n",
    "    def __init__(self, \n",
    "                 normaliser='init_primal_bound', \n",
    "                 transform_with_log=False,\n",
    "                 epsilon=None):\n",
    "        '''\n",
    "        Args:\n",
    "            normaliser ('init_primal_bound', 'curr_primal_bound'): What to normalise\n",
    "                with respect to in the numerator and denominator to calculate\n",
    "                the per-step normalsed LP gain reward.\n",
    "            transform_with_log: If True, will transform the reward by doing\n",
    "                reward = sign(reward) * log(1 + |reward|) -> helps reduce variance\n",
    "                of reward as in https://arxiv.org/pdf/1704.03732.pdf\n",
    "            epsilon (None, float): If not None, will set score of nodes which\n",
    "                were pruned, infeasible, or outside of bounds to epsilon (rather than\n",
    "                0 if added or rather than not considering at all if never added to tree).\n",
    "                N.B. epsilon should be a small number e.g. 1e-6. N.B.2. Current\n",
    "                implementation assumes each branching decision results in 2 child\n",
    "                nodes (regardless of whether or not SCIP stores these in memory).\n",
    "        '''\n",
    "        self.normaliser = normaliser\n",
    "        self.transform_with_log = transform_with_log\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def before_reset(self, model):\n",
    "        self.prev_node = None\n",
    "        self.prev_node_id = None\n",
    "        self.prev_primal_bound = None\n",
    "        self.init_primal_bound = None\n",
    "\n",
    "    def extract(self, model, done):\n",
    "        m = model.as_pyscipopt()\n",
    "\n",
    "        if self.prev_node_id is None:\n",
    "            # not yet started, update prev node for next step\n",
    "            self.prev_node = m.getCurrentNode()\n",
    "            self.tree = SearchTree(model)\n",
    "            if self.prev_node is not None:\n",
    "                self.prev_node_id = copy.deepcopy(self.prev_node.getNumber())\n",
    "                self.prev_primal_bound = m.getPrimalbound()\n",
    "                self.init_primal_bound = m.getPrimalbound()\n",
    "            return 0\n",
    "\n",
    "        # update search tree with current model state\n",
    "        self.tree.update_tree(model)\n",
    "        \n",
    "        # collect node stats from children introduced from previous branching decision\n",
    "        prev_node_lb = self.tree.tree.nodes[self.prev_node_id]['lower_bound']\n",
    "        prev_node_child_ids = [child for child in self.tree.tree.successors(self.prev_node_id)]\n",
    "        prev_node_child_lbs = [self.tree.tree.nodes[child]['lower_bound'] for child in prev_node_child_ids]\n",
    "\n",
    "        # calc reward for previous branching decision\n",
    "        if len(prev_node_child_lbs) > 0:\n",
    "            # use child lp gains to retrospectively calculate a score for the previous branching decision\n",
    "            score = -1\n",
    "            for child_node_lb in prev_node_child_lbs:\n",
    "                if self.normaliser == 'curr_primal_bound':\n",
    "                    # use primal bound of step branching action was taken\n",
    "                    score *= (self.prev_primal_bound - child_node_lb) / (self.prev_primal_bound - prev_node_lb)\n",
    "                elif self.normaliser == 'init_primal_bound':\n",
    "                    # use init primal bound\n",
    "                    score *= (self.init_primal_bound - child_node_lb) / (self.init_primal_bound - prev_node_lb)\n",
    "                else:\n",
    "                    raise Exception(f'Unrecognised normaliser {self.normaliser}')\n",
    "            if self.epsilon is not None:\n",
    "                # consider child nodes which were never added to search tree by SCIP\n",
    "                for _ in range(int(2-len(prev_node_child_lbs))):\n",
    "                    score *= self.epsilon\n",
    "        else:\n",
    "            # previous branching decision led to all child nodes being pruned, infeasible, or outside bounds -> don't punish brancher\n",
    "            if self.epsilon is not None:\n",
    "                score = -1 * (self.epsilon**2)\n",
    "            else:\n",
    "                score = 0\n",
    "        self.tree.tree.nodes[self.prev_node_id]['score'] = score\n",
    "\n",
    "        if m.getCurrentNode() is not None:\n",
    "            # update stats for next step\n",
    "            self.prev_node = m.getCurrentNode()\n",
    "            self.prev_node_id = copy.deepcopy(self.prev_node.getNumber())\n",
    "            self.prev_primal_bound = m.getPrimalbound()\n",
    "        else:\n",
    "            # instance completed, no current focus node\n",
    "            pass\n",
    "\n",
    "        if self.transform_with_log:\n",
    "            sign = math.copysign(1, score)\n",
    "            score = sign * math.log(1 + abs(score), 10)\n",
    "\n",
    "        if score < -1:\n",
    "            print('Score < -1 found.')\n",
    "            for node in self.tree.tree.nodes():\n",
    "                print(f'Node {node} lb: {self.tree.tree.nodes[node][\"lower_bound\"]}')\n",
    "            raise Exception()\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-trees episode construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "class RetroBranching:\n",
    "    def __init__(self, \n",
    "                 normaliser='init_primal_bound', \n",
    "                 min_subtree_depth=1, \n",
    "                 retro_trajectory_construction='deepest',\n",
    "                 remove_nonoptimal_fathomed_leaves=False,\n",
    "                 debug_mode=False):\n",
    "        '''\n",
    "        Waits until end of episode to calculate rewards for each step, then retrospectively\n",
    "        goes back through each step in the episode and calculates reward for that step.\n",
    "        I.e. reward returned will be None until the end of the episode, at which\n",
    "        point a dict mapping episode_step_idx for optimal path nodes to reward will be returned.\n",
    "\n",
    "        The terminal sub-tree will first retrospectively construct an episode from the root node\n",
    "        to the opimal node (i.e. the 'optimal path') and make this as one episode. Then, it will\n",
    "        iteratively go through all other nodes in the B&B tree not already included in a retrospective\n",
    "        sub-tree episode path and construct sub-trees randomly untill all nodes experiences by the agent\n",
    "        are included in an episode. Will then return a list, where each element in the list is a dict\n",
    "        mapping the step index in the original episode and the corresponding reward received by the agent.\n",
    "        \n",
    "        Args:\n",
    "            normaliser ('init_primal_bound', 'curr_primal_bound'): What to normalise\n",
    "                with respect to in the numerator and denominator to calculate\n",
    "                the per-step normalsed LP gain reward.\n",
    "            min_subtree_depth (int): Minimum depth of sub-tree (i.e. minimum length of sub-tree episode).\n",
    "            retro_trajectory_construction ('random', 'deepest'): Which policy to use when choosing a leaf node as the\n",
    "                final node to construct a sub-tree.\n",
    "            remove_nonoptimal_fathomed_leaves (bool): If True, at end of episode, will remove\n",
    "                all leaves in tree which were fathomed (had score == 0) except optimal path leaf \n",
    "                so that no non-optimal sub-tree will have been fathomed and contain a \n",
    "                node/experience with score == 0.\n",
    "        '''\n",
    "        self.min_subtree_depth = min_subtree_depth\n",
    "        self.retro_trajectory_construction = retro_trajectory_construction\n",
    "        self.normalised_lp_gain = NormalisedLPGain(normaliser=normaliser) # normalised lp gain reward tracker\n",
    "        self.remove_nonoptimal_fathomed_leaves = remove_nonoptimal_fathomed_leaves\n",
    "        self.debug_mode = debug_mode\n",
    "\n",
    "    def before_reset(self, model):\n",
    "        self.started = False\n",
    "        self.normalised_lp_gain.before_reset(model)\n",
    "        \n",
    "    def get_path_node_scores(self, tree, path):\n",
    "        return [tree.nodes[node]['score'] for node in path]\n",
    "        \n",
    "    def conv_root_final_pair_to_step_idx_reward_map(self, root_node, final_node, check_depth=True):\n",
    "        path = shortest_path(self.normalised_lp_gain.tree.tree, source=root_node, target=final_node)\n",
    "        \n",
    "        # register which nodes have been directly included in the sub-tree\n",
    "        for node in path:\n",
    "            self.nodes_added.add(node)\n",
    "            \n",
    "        if check_depth:\n",
    "            if len(path) < self.min_subtree_depth:\n",
    "                # subtree not deep enough, do not use episode (but count all nodes as having been added)\n",
    "                return None\n",
    "        \n",
    "        # get rewards at each step in sub-tree episode\n",
    "        path_node_rewards = self.get_path_node_scores(self.normalised_lp_gain.tree.tree, path)\n",
    "\n",
    "        # get episode step indices at which each node in sub-tree was visited\n",
    "        path_to_step_idx = {node: self.visited_nodes_to_step_idx[node] for node in path}\n",
    "\n",
    "        # map each path node episode step idx to its corresponding reward\n",
    "        step_idx_to_reward = {step_idx: r for step_idx, r in zip(list(path_to_step_idx.values()), path_node_rewards)}\n",
    "        \n",
    "        return step_idx_to_reward\n",
    "\n",
    "    def extract(self, model, done):\n",
    "        # update normalised LP gain tracker\n",
    "        _ = self.normalised_lp_gain.extract(model, done)\n",
    "\n",
    "        # m = model.as_pyscipopt()\n",
    "        # curr_node = m.getCurrentNode()\n",
    "\n",
    "        # if not self.started:\n",
    "            # if curr_node is not None:\n",
    "                # self.started = True\n",
    "            # return None\n",
    "        \n",
    "        # if curr_node is not None:\n",
    "            # # instance not yet finished\n",
    "            # return None\n",
    "\n",
    "        if not done:\n",
    "            return None\n",
    "        else:\n",
    "            if self.normalised_lp_gain.tree.tree.graph['root_node'] is None:\n",
    "                # instance was pre-solved\n",
    "                return [{0: 0}]\n",
    "\n",
    "            # instance finished, retrospectively create subtree episode paths\n",
    "            subtrees_step_idx_to_reward = []\n",
    "\n",
    "            # keep track of which nodes have been added to a sub-tree\n",
    "            self.nodes_added = set()\n",
    "            \n",
    "            if self.debug_mode:\n",
    "                print('\\nB&B tree:')\n",
    "                print(f'All nodes saved: {self.normalised_lp_gain.tree.tree.nodes()}')\n",
    "                print(f'Visited nodes: {self.normalised_lp_gain.tree.tree.graph[\"visited_node_ids\"]}')\n",
    "                self.normalised_lp_gain.tree.render()\n",
    "\n",
    "            # remove nodes which were never visited by the brancher and therefore do not have a score or next state\n",
    "            nodes = [node for node in self.normalised_lp_gain.tree.tree.nodes]\n",
    "            for node in nodes:\n",
    "                if 'score' not in self.normalised_lp_gain.tree.tree.nodes[node]:\n",
    "                    # node never visited by brancher -> do not consider\n",
    "                    self.normalised_lp_gain.tree.tree.remove_node(node)\n",
    "                    if node in self.normalised_lp_gain.tree.tree.graph['visited_node_ids']:\n",
    "                        # hack: SCIP sometimes returns large int rather than None node_id when episode finished\n",
    "                        # since never visited this node (since no score assigned), do not count this node as having been visited when calculating paths below\n",
    "                        self.normalised_lp_gain.tree.tree.graph['visited_node_ids'].remove(node)\n",
    "\n",
    "            # map which nodes were visited at which step in episode\n",
    "            # visited_nodes = [list(node.keys())[0] for node in self.normalised_lp_gain.tree.tree.graph['visited_nodes']]\n",
    "            self.visited_nodes_to_step_idx = {node: idx for idx, node in enumerate(self.normalised_lp_gain.tree.tree.graph['visited_node_ids'])}\n",
    "\n",
    "            # get optimal path\n",
    "            root_node = list(self.normalised_lp_gain.tree.tree.graph['root_node'].keys())[0]\n",
    "            # final_node = list(self.normalised_lp_gain.tree.tree.graph['visited_nodes'][-1].keys())[0]\n",
    "            final_node = self.normalised_lp_gain.tree.tree.graph['visited_node_ids'][-1]\n",
    "            subtrees_step_idx_to_reward.append(self.conv_root_final_pair_to_step_idx_reward_map(root_node, final_node, check_depth=False))\n",
    "\n",
    "            if self.remove_nonoptimal_fathomed_leaves:\n",
    "                for node in nodes:\n",
    "                    if node in self.normalised_lp_gain.tree.tree.nodes.keys():\n",
    "                        if self.normalised_lp_gain.tree.tree.nodes[node]['score'] == 0 and node != final_node:\n",
    "                            # node fathomed and not in optimal path, remove\n",
    "                            self.normalised_lp_gain.tree.tree.remove_node(node)\n",
    "                            if self.debug_mode:\n",
    "                                print(f'Removed non-optimal fathomed leaf node {node}')\n",
    "            \n",
    "            # create sub-tree episodes from remaining B&B nodes visited by agent\n",
    "            while True:\n",
    "                # create depth first search sub-trees from nodes still leftover\n",
    "                nx_subtrees = []\n",
    "                \n",
    "                # construct sub-trees containing prospective sub-tree episode(s) from remaining nodes\n",
    "                for node in self.nodes_added:\n",
    "                    children = [child for child in self.normalised_lp_gain.tree.tree.successors(node)]\n",
    "                    for child in children:\n",
    "                        if child not in self.nodes_added:\n",
    "                            nx_subtrees.append(dfs_tree(self.normalised_lp_gain.tree.tree, child))\n",
    "                            \n",
    "                for i, subtree in enumerate(nx_subtrees):\n",
    "                    # init node scores for nodes in subtree (since these are not transferred into new subtree)\n",
    "                    for node in subtree.nodes:\n",
    "                        subtree.nodes[node]['score'] = self.normalised_lp_gain.tree.tree.nodes[node]['score']\n",
    "\n",
    "                    # get root of sub-tree\n",
    "                    for root_node in subtree.nodes:\n",
    "                        if subtree.in_degree(root_node) == 0:\n",
    "                            # node is root\n",
    "                            break\n",
    "\n",
    "                    # get a path by choosing a leaf node as the final node in the path\n",
    "                    leaf_nodes = [node for node in subtree.nodes() if subtree.out_degree(node) == 0]\n",
    "                    if self.retro_trajectory_construction == 'random':\n",
    "                        # randomly choose leaf node as final node\n",
    "                        final_node = leaf_nodes[random.choice(range(len(leaf_nodes)))]\n",
    "                    elif self.retro_trajectory_construction == 'deepest':\n",
    "                        # choose leaf node which would lead to deepest subtree as final node\n",
    "                        depths = [len(shortest_path(subtree, source=root_node, target=leaf_node)) for leaf_node in leaf_nodes]\n",
    "                        final_node = leaf_nodes[depths.index(max(depths))]\n",
    "                    else:\n",
    "                        raise Exception(f'Unrecognised retro_trajectory_construction {self.retro_trajectory_construction}')\n",
    "                        \n",
    "                    subtree_step_idx_to_reward = self.conv_root_final_pair_to_step_idx_reward_map(root_node, final_node, check_depth=True)\n",
    "                    if subtree_step_idx_to_reward is not None:\n",
    "                        subtrees_step_idx_to_reward.append(subtree_step_idx_to_reward)\n",
    "                    else:\n",
    "                        # subtree was not deep enough to be added\n",
    "                        pass\n",
    "\n",
    "                if len(nx_subtrees) == 0:\n",
    "                    # all sub-trees added\n",
    "                    break\n",
    "                    \n",
    "            if self.debug_mode:\n",
    "                print(f'visited_nodes_to_step_idx: {self.visited_nodes_to_step_idx}')\n",
    "                step_idx_to_visited_nodes = {val: key for key, val in self.visited_nodes_to_step_idx.items()}\n",
    "                for i, ep in enumerate(subtrees_step_idx_to_reward):\n",
    "                    print(f'>>> sub-tree episode {i+1}: {ep}')\n",
    "                    ep_path = [step_idx_to_visited_nodes[idx] for idx in ep.keys()]\n",
    "                    print(f'path: {ep_path}')\n",
    "            \n",
    "            return subtrees_step_idx_to_reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "seed = 0\n",
    "seed_stochastic_modules_globally(default_seed=seed)\n",
    "\n",
    "agent = PseudocostBranchingAgent()\n",
    "\n",
    "env = EcoleBranching(observation_function='default',\n",
    "                      information_function='default',\n",
    "                      reward_function='default',\n",
    "                      scip_params='default')\n",
    "env.seed(seed)\n",
    "\n",
    "instances = ecole.instance.SetCoverGenerator(n_rows=300, n_cols=300, density=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "obs = None\n",
    "custom_reward = RetroBranching(normaliser='init_primal_bound', \n",
    "                                         min_subtree_depth=1, \n",
    "                                         retro_trajectory_construction='deepest',\n",
    "                                         remove_nonoptimal_fathomed_leaves=True,\n",
    "                                         debug_mode=True)\n",
    "while obs is None:\n",
    "    env.seed(seed)\n",
    "    instance = next(instances)\n",
    "    custom_reward.before_reset(instance)\n",
    "    agent.before_reset(instance)\n",
    "    obs, action_set, reward, done, info = env.reset(instance)\n",
    "    _custom_reward = custom_reward.extract(env.model, done)\n",
    "    \n",
    "t = 1\n",
    "instance_transitions = []\n",
    "prev_obs = copy.deepcopy(obs)\n",
    "tree = custom_reward.normalised_lp_gain.tree\n",
    "while not done:\n",
    "    # select branching action\n",
    "    action, action_idx = agent.action_select(action_set, model=env.model, done=done)\n",
    "    obs, action_set, reward, done, info = env.step(action)\n",
    "    _custom_reward = custom_reward.extract(env.model, done)\n",
    "    \n",
    "    if done:\n",
    "        obs = copy.deepcopy(prev_obs)\n",
    "    \n",
    "    # store transition\n",
    "    instance_transitions.append({'obs': prev_obs,\n",
    "                               'action': action,\n",
    "#                                'reward': reward['normalised_lp_gain'],\n",
    "                               'reward': reward['num_nodes'],\n",
    "                               'done': done,\n",
    "                               'next_obs': obs})\n",
    "    \n",
    "    # update prev obs\n",
    "    prev_obs = copy.deepcopy(obs)\n",
    "    \n",
    "    m = env.model.as_pyscipopt()\n",
    "    print(f'Step {t} | Reward: {reward[\"num_nodes\"]:.3f} | primal bound: {m.getPrimalbound()} | dual bound: {m.getDualbound()}')\n",
    "    print(f'Custom reward: {_custom_reward}')\n",
    "    \n",
    "    # update search tree and analyse branching action\n",
    "    tree.update_tree(env.model)\n",
    "#     tree.render()\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    t += 1\n",
    "    \n",
    "m = env.model.as_pyscipopt()\n",
    "print(f'\\nFinished | primal bound: {m.getPrimalbound()} | dual bound: {m.getDualbound()} | # nodes: {m.getNTotalNodes()} | Final node: {tree.tree.graph[\"visited_nodes\"][-1]}')\n",
    "print(f'Custom reward: {_custom_reward}')\n",
    "tree.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlgnn",
   "language": "python",
   "name": "rlgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
