{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pyscipopt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N.B. Need to unzip .mps.gz* files to make them .mps files\n",
    "\n",
    "# set paths to folders with .mps files\n",
    "paths = {'item_placement': '/scratch/datasets/retro_branching/ml4co/instances/1_item_placement/train/',\n",
    "         'load_balancing': None,\n",
    "         'anonymous': '/scratch/datasets/retro_branching/ml4co/instances/3_anonymous/train/'}\n",
    "paths = {'item_placement': '/scratch/datasets/retro_branching/ml4co/instances/1_item_placement/train/',\n",
    "         'load_balancing': '/scratch/datasets/retro_branching/ml4co/instances/2_load_balancing/train/',\n",
    "         'anonymous': '/scratch/datasets/retro_branching/ml4co/instances/3_anonymous/train/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get .mps file names\n",
    "filenames = {}\n",
    "for dataset, path in paths.items():\n",
    "    if path is not None:\n",
    "        filenames[dataset] = glob.glob(path+'*.mps')\n",
    "        print('{} #mps files: {}'.format(path, len(filenames[dataset])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# characterise\n",
    "\n",
    "def characterise_pyscipopt_instance(m):\n",
    "    if type(m) == str:\n",
    "        # is file path\n",
    "        filename = copy.deepcopy(m)\n",
    "        m = pyscipopt.Model()\n",
    "        m.readProblem(filename)\n",
    "    summary = {}\n",
    "    summary['filename'] = m.getProbName()\n",
    "    summary['num_vars'] = m.getNVars()\n",
    "    summary['num_constraints'] = m.getNConss()\n",
    "    summary['num_int_vars'] = m.getNIntVars()\n",
    "    summary['num_binary_vars'] = m.getNBinVars()\n",
    "    return summary\n",
    "    \n",
    "summary_dict = {}\n",
    "for dataset in filenames.keys():\n",
    "    summary_dict[dataset] = defaultdict(list)\n",
    "    pbar = tqdm(total=len(filenames[dataset]), \n",
    "                          desc=dataset,\n",
    "                          leave=True)\n",
    "    for file in filenames[dataset]:\n",
    "        summary = characterise_pyscipopt_instance(file)\n",
    "        for key in summary.keys():\n",
    "            summary_dict[dataset][key].append(summary[key])\n",
    "        pbar.update(1)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_context(context='paper') # paper notebook talk poster\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "for dataset in summary_dict.keys():\n",
    "    print(dataset)\n",
    "    for key in summary_dict[dataset].keys():\n",
    "        if key != 'filename':\n",
    "            if len(summary_dict[dataset][key]) != 0:\n",
    "                sns.histplot(data=pd.DataFrame(summary_dict[dataset]), x=key)\n",
    "                plt.title(dataset)\n",
    "                plt.show()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print table (assuming from above plots that all instances in each data set have same characteristics)\n",
    "table_dict = defaultdict(list)\n",
    "for dataset in summary_dict.keys():\n",
    "    if dataset != 'anonymous': # anonymous dataset instances do not all have same characteristics\n",
    "        table_dict['dataset'].append(dataset)\n",
    "        table_dict['num_instances'].append(len(summary_dict[dataset]['filename']))\n",
    "        for key in summary_dict[dataset].keys():\n",
    "            if key != 'filename':\n",
    "                if len(summary_dict[dataset][key]) != 0:\n",
    "                    table_dict[key].append(summary_dict[dataset][key][0])\n",
    "                else:\n",
    "                    table_dict[key].append(0)\n",
    "display(pd.DataFrame(table_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlgnn",
   "language": "python",
   "name": "rlgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
