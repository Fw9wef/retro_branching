{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n",
    "This notebook is for performing validation rollouts to test trained policies etc. on some test instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from retro_branching.environments import EcoleBranching\n",
    "from retro_branching.networks import BipartiteGCN\n",
    "from retro_branching.agents import REINFORCEAgent, StrongBranchingAgent\n",
    "from retro_branching.validators import ReinforcementLearningValidator\n",
    "from retro_branching.utils import plot_val_line\n",
    "\n",
    "import ecole\n",
    "import torch\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_recent_agent_checkpoint_foldername(agent_path):\n",
    "    '''Given a path to a folders named <name>_<number>, will return foldername with highest <number>.'''\n",
    "    foldernames = [name.split('_') for name in os.listdir(agent_path)]\n",
    "    idx_to_num = {idx: int(num) for idx, num in zip(range(len(foldernames)), [name[-1] for name in foldernames])}\n",
    "    latest_idx = max(idx_to_num, key=idx_to_num.get)\n",
    "    foldername = [name for name in os.listdir(agent_path)][latest_idx]\n",
    "    return foldername"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise Agents\n",
    "\n",
    "Load any saved NN parameters and initialise any agents you want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "DEVICE = 'cuda:1'\n",
    "agents = {}\n",
    "\n",
    "# # LOAD RL AGENTS\n",
    "# ids = [57, 58, 60, 65]\n",
    "# for i in ids:\n",
    "#     # load agent params\n",
    "#     agent = 'rl_gnn_{}'.format(i)\n",
    "#     agent_path = '/scratch/datasets/retro_branching/reinforce_learner/rl_gnn/{}/'.format(agent)\n",
    "#     foldername = get_most_recent_agent_checkpoint_foldername(agent_path)\n",
    "# #     foldername='checkpoint_5'\n",
    "#     path = '{}{}/'.format(agent_path, foldername)\n",
    "#     policy_network = BipartiteGCN(DEVICE)\n",
    "#     policy_network.load_state_dict(torch.load(path+'trained_params.pkl'))\n",
    "\n",
    "#     # init agent\n",
    "#     agent = REINFORCEAgent(policy_network=policy_network, device=DEVICE, name=agent_name)\n",
    "#     agent.eval() # turn on evaluation mode\n",
    "#     agents[agent_name] = agent\n",
    "\n",
    "# LOAD GNN AGENT (NO RL)\n",
    "policy_network = BipartiteGCN(DEVICE)\n",
    "agent = 'gnn_21'\n",
    "agent_path = '/scratch/datasets/retro_branching/supervised_learner/gnn/{}/'.format(agent)\n",
    "foldername = get_most_recent_agent_checkpoint_foldername(agent_path)\n",
    "# foldername='checkpoint_5'\n",
    "path = '{}{}/'.format(agent_path, foldername)\n",
    "print(path)\n",
    "policy_network.load_state_dict(torch.load(path+'trained_params.pkl', map_location=DEVICE))\n",
    "agent = REINFORCEAgent(policy_network=policy_network, device=DEVICE, name='gnn_100k')\n",
    "agent.eval() # turn on evaluation mode\n",
    "agents['gnn_100k'] = agent\n",
    "\n",
    "DEVICE = 'cuda:0'\n",
    "policy_network = BipartiteGCN(DEVICE)\n",
    "path = '../scripts/'\n",
    "print(path)\n",
    "policy_network.load_state_dict(torch.load(path+'trained_params_dict_disabler.pkl', map_location=DEVICE))\n",
    "agent = REINFORCEAgent(policy_network=policy_network, device=DEVICE, name='gnn_1k')\n",
    "agent.eval() # turn on evaluation mode\n",
    "agents['gnn_1k'] = agent\n",
    "\n",
    "# LOAD STRONG BRANCHING AGENT\n",
    "agent = StrongBranchingAgent(name='sb')\n",
    "agents['sb'] = agent\n",
    "print('Initialised agents {}'.format(agents.keys()))\n",
    "\n",
    "print(agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Validation Rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instances = ecole.instance.SetCoverGenerator(n_rows=100, n_cols=100, density=0.05)\n",
    "instances = ecole.instance.SetCoverGenerator(n_rows=500, n_cols=1000, density=0.05)\n",
    "print('Initialised instances.')\n",
    "\n",
    "\n",
    "# init envs\n",
    "envs = {}\n",
    "for agent_name in agents.keys():\n",
    "    envs[agent_name] = EcoleBranching()\n",
    "print('Initialised agent envs.')\n",
    "\n",
    "# metrics\n",
    "metrics = ['num_nodes', 'solving_time', 'lp_iterations']\n",
    "print('Initialised metrics.')\n",
    "\n",
    "\n",
    "validator = ReinforcementLearningValidator(agents=agents,\n",
    "                                           envs=envs,\n",
    "                                           instances=instances,\n",
    "                                           metrics=metrics,\n",
    "                                           seed=0,\n",
    "                                           turn_off_heuristics=False,\n",
    "                                           threshold_difficulty=None,\n",
    "                                           epoch_log_frequency=1)\n",
    "validator.test(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Validation Rollout Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "plot_dicts = {metric: nested_dict() for metric in validator.metrics}\n",
    "\n",
    "for agent in validator.epochs_log.keys():\n",
    "    for metric in validator.metrics:\n",
    "        plot_dicts[metric][agent]['y_values'] = validator.epochs_log[agent][metric]\n",
    "        plot_dicts[metric][agent]['x_values'] = list(range(len(validator.epochs_log[agent][metric])))\n",
    "        print('Agent {} mean {}: {}'.format(agent, metric, np.mean(validator.epochs_log[agent][metric])))\n",
    "        \n",
    "res = 1\n",
    "for metric in plot_dicts.keys():\n",
    "    _ = plot_val_line(plot_dicts[metric],\n",
    "                      xlabel='Epoch',\n",
    "                      ylabel='{}'.format(metric),\n",
    "                      show_fig=True)\n",
    "    _ = plot_val_line(plot_dicts[metric],\n",
    "                      xlabel='Epoch',\n",
    "                      ylabel='Mean {}'.format(metric),\n",
    "                      smooth_data_res=res,\n",
    "                      show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlgnn",
   "language": "python",
   "name": "rlgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
