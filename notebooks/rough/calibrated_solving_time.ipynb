{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From DeepMind paper: https://arxiv.org/pdf/2012.13349.pdf\n",
    "\n",
    "**Calibrated time:** The total evaluation workload across all datasets and comparisons requires\n",
    "more than 160,000 MIP solves and nearly a million CPU and GPU hours. To meet the compute\n",
    "requirements, we use a shared, heterogeneous compute cluster. Accurate running time measurement on such a cluster is difficult because the tasks may be scheduled on machines with different\n",
    "hardware, and interference from other unrelated tasks on the same machine increases the variance\n",
    "of solve times. To improve accuracy, for each solve task, we periodically solve a small calibration\n",
    "MIP on a different thread from the solve task on the same machine. We use an estimate of the\n",
    "number of calibration MIP solves during the solve task on the same machine to measure time,\n",
    "which is significantly less sensitive to hardware heterogeneity and interference. This quantity is then\n",
    "converted into a time value using the calibration MIP’s solve time on a reference machine. Section\n",
    "12.7 gives the details. Results for four instances from MIPLIB show a 1.5× to 30× reduction in\n",
    "the coefficient of variation of time measurements compared to measuring wall clock time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU calibrated time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from retro_branching.environments import EcoleConfiguring\n",
    "\n",
    "import ecole\n",
    "import time\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "num_solves = 1000\n",
    "seed = 5\n",
    "\n",
    "env = EcoleConfiguring(observation_function='default',\n",
    "                       information_function='default',\n",
    "                       scip_params='default')\n",
    "\n",
    "ecole.seed(seed)\n",
    "instance = next(ecole.instance.SetCoverGenerator(n_rows=500, n_cols=1000, density=0.05))\n",
    "instance_before_reset = instance.copy_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solving_times = []\n",
    "for solve in range(1, num_solves+1):\n",
    "    env.seed(seed)\n",
    "    _, _, _, _, _ = env.reset(instance_before_reset.copy_orig())\n",
    "    start_t = time.time()\n",
    "    _, _, _, _, info = env.step({})\n",
    "    solving_times.append(time.time() - start_t)\n",
    "    print(f'Solved {solve} of {num_solves} completed in {solving_times[-1]:.3f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "calibration_config = {'seed': seed,\n",
    "                      'device': 'cpu',\n",
    "                      'nrows': 500,\n",
    "                      'ncols': 1000,\n",
    "                      'num_solves': num_solves,\n",
    "                      'solving_times': solving_times,\n",
    "                      'mean_solving_time': np.mean(solving_times)}\n",
    "with open('cpu_calibration_config.json', 'w') as f:\n",
    "    json.dump(calibration_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calibration_config['mean_solving_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU calibrated time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from retro_branching.environments import EcoleBranching\n",
    "from retro_branching.agents import Agent\n",
    "\n",
    "import ecole\n",
    "import torch\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "num_warmup_inferences = 1000\n",
    "num_inferences = 10000\n",
    "seed = 5\n",
    "nrows = 7500\n",
    "ncols = 7500\n",
    "\n",
    "env = EcoleBranching(observation_function='default',\n",
    "                     information_function='default',\n",
    "                     reward_function='default',\n",
    "                     scip_params='default')\n",
    "\n",
    "ecole.seed(seed)\n",
    "instance = next(ecole.instance.SetCoverGenerator(n_rows=nrows, n_cols=ncols, density=0.05))\n",
    "instance_before_reset = instance.copy_orig()\n",
    "\n",
    "# init calibration agent\n",
    "device = 'cuda:0'\n",
    "path = '/scratch/datasets/retro_branching/supervised_learner/gnn/gnn_343/checkpoint_233/'\n",
    "config = path + 'config.json'\n",
    "calibration_agent = Agent(device=device, config=config)\n",
    "for network_name, network in calibration_agent.get_networks().items():\n",
    "    if network_name == 'networks':\n",
    "        # TEMPORARY: Fix typo\n",
    "        network_name = 'network'\n",
    "    if network is not None:\n",
    "        try:\n",
    "            # see if network saved under same var as 'network_name'\n",
    "            calibration_agent.__dict__[network_name].load_state_dict(torch.load(path+f'/{network_name}_params.pkl', map_location=device))\n",
    "        except KeyError:\n",
    "            # network saved under generic 'network' var (as in Agent class)\n",
    "            calibration_agent.__dict__['network'].load_state_dict(torch.load(path+f'/{network_name}_params.pkl', map_location=device))\n",
    "    else:\n",
    "        pass\n",
    "calibration_agent.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_state_tensors_from_ecole_obs(obs, device):\n",
    "    return (torch.from_numpy(obs.row_features.astype(np.float32)).to(device), \n",
    "            torch.LongTensor(obs.edge_features.indices.astype(np.int16)).to(device),\n",
    "            torch.from_numpy(obs.column_features.astype(np.float32)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inference_times = []\n",
    "\n",
    "env.seed(seed)\n",
    "\n",
    "# reset calibration env\n",
    "calibration_agent.before_reset(instance_before_reset.copy_orig())\n",
    "obs, action_set, reward, done, info = env.reset(instance_before_reset.copy_orig())\n",
    "\n",
    "action_set = action_set.astype(int)\n",
    "obs = extract_state_tensors_from_ecole_obs(obs, device)\n",
    "\n",
    "# do num_warmup_inferences\n",
    "for inference in range(num_warmup_inferences):\n",
    "    action, _ = calibration_agent.action_select(action_set=action_set, obs=obs, munchausen_tau=0, epsilon=0, model=env.model, done=done, agent_idx=0)\n",
    "    print(f'Completed {inference+1} of {num_warmup_inferences} warm-up inferences')\n",
    "print(f'Completed all {num_warmup_inferences} warm-up inferences.\\n')\n",
    "\n",
    "# do num_inferences\n",
    "for inference in range(num_inferences):\n",
    "    inference_start_t = time.time_ns()\n",
    "    action, _ = calibration_agent.action_select(action_set=action_set, obs=obs, munchausen_tau=0, epsilon=0, model=env.model, done=done, agent_idx=0)\n",
    "    torch.cuda.synchronize(device=device)\n",
    "    inference_times.append((time.time_ns() - inference_start_t)*1e-9)\n",
    "\n",
    "    print(f'Completed {inference+1} of {num_inferences} inferences --> curr mean inference time: {np.mean(inference_times)} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # warm-up solves\n",
    "# for solve in range(1, num_warmup_solves+1):\n",
    "#     env.seed(seed)\n",
    "    \n",
    "#     # reset calibration env\n",
    "#     calibration_agent.before_reset(instance_before_reset.copy_orig())\n",
    "#     obs, action_set, reward, done, info = env.reset(instance_before_reset.copy_orig())\n",
    "\n",
    "#     # solve calibration instance\n",
    "#     while not done:\n",
    "#         action_set = action_set.astype(int)\n",
    "#         obs = extract_state_tensors_from_ecole_obs(obs, device)\n",
    "#         action, _ = calibration_agent.action_select(action_set=action_set, obs=obs, munchausen_tau=0, epsilon=0, model=env.model, done=done, agent_idx=0)\n",
    "#         obs, action_set, reward, done, info = env.step(action)\n",
    "#         print(info['num_nodes'])\n",
    "\n",
    "#     print(f'Solved {solve} of {num_warmup_solves} warm-up instances with {info[\"num_nodes\"]} nodes')\n",
    "# print(f'Completed warm-up solves. Beginning to solve calibration instance {num_solves} times...\\n')\n",
    "\n",
    "\n",
    "# inference_times = []\n",
    "# for solve in range(1, num_solves+1):\n",
    "#     env.seed(seed)\n",
    "    \n",
    "#     # reset calibration env\n",
    "#     calibration_agent.before_reset(instance_before_reset.copy_orig())\n",
    "#     obs, action_set, reward, done, info = env.reset(instance_before_reset.copy_orig())\n",
    "\n",
    "#     # solve calibration instance and save inference times\n",
    "#     while not done:\n",
    "#         action_set = action_set.astype(int)\n",
    "#         obs = extract_state_tensors_from_ecole_obs(obs, device)\n",
    "#         inference_start_t = time.time_ns()\n",
    "#         action, _ = calibration_agent.action_select(action_set=action_set, obs=obs, munchausen_tau=0, epsilon=0, model=env.model, done=done, agent_idx=0)\n",
    "#         torch.cuda.synchronize(device=device)\n",
    "#         inference_times.append((time.time_ns() - inference_start_t)*1e-9)\n",
    "#         obs, action_set, reward, done, info = env.step(action)\n",
    "\n",
    "#     print(f'Solved {solve} of {num_solves} instances with {info[\"num_nodes\"]} nodes --> curr mean inference time: {np.mean(inference_times)} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "calibration_config = {'seed': seed,\n",
    "                      'device': 'cuda',\n",
    "                      'nrows': nrows,\n",
    "                      'ncols': ncols,\n",
    "                      'num_inferences': num_inferences,\n",
    "                      'inference_times': inference_times,\n",
    "                      'mean_inference_time': np.mean(inference_times)}\n",
    "with open('gpu_calibration_config.json', 'w') as f:\n",
    "    json.dump(calibration_config, f)\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calibration_config['mean_inference_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of using calibrated time\n",
    "\n",
    "N.B. In below we are recording the total calibrated solve time, but could also record the per-step calibrated solve time, which is helpful for plotting metric (e.g. primal dual gap) evolution throughout the instance solving process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "from retro_branching.environments import EcoleBranching\n",
    "from retro_branching.agents import PseudocostBranchingAgent\n",
    "\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "num_episodes = 20\n",
    "calibration_freq = 10 # num instances to solve with agent before starting new calibration threads\n",
    "num_calibrations = 10 # num repeats of calibration to perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "# calibration\n",
    "def solve_calibration_instance(calibration_config, calibration_solve_times):\n",
    "    calibration_env = EcoleConfiguring(observation_function='default',\n",
    "                                   information_function='default',\n",
    "                                   scip_params='default')\n",
    "    calibration_generator = ecole.instance.SetCoverGenerator(n_rows=calibration_config['nrows'], \n",
    "                                                             n_cols=calibration_config['ncols'], \n",
    "                                                             density=0.05)\n",
    "    calibration_generator.seed(calibration_config['seed'])\n",
    "    calibration_instance = next(calibration_generator)\n",
    "\n",
    "    calibration_env.seed(calibration_config['seed'])\n",
    "    _, _, _, _, info = calibration_env.reset(calibration_instance.copy_orig())\n",
    "    \n",
    "    start_t = time.time()\n",
    "    _, _, _, _, info = calibration_env.step({})\n",
    "    calibration_solve_times.append(time.time() - start_t)\n",
    "    print('finished calibration')\n",
    "\n",
    "\n",
    "\n",
    "# agent\n",
    "env = EcoleBranching(observation_function='default',\n",
    "                     information_function='default',\n",
    "                     reward_function='default',\n",
    "                     scip_params='default')\n",
    "\n",
    "agent = PseudocostBranchingAgent()\n",
    "\n",
    "ecole.seed(seed)\n",
    "instances = ecole.instance.SetCoverGenerator(n_rows=500, n_cols=1000, density=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_solve_times = []\n",
    "for episode_counter in range(num_episodes):\n",
    "    if episode_counter % calibration_freq == 0:\n",
    "        # perform calibration\n",
    "        threads = list()\n",
    "        calibration_solve_times = []\n",
    "        for _ in range(10):\n",
    "            x = threading.Thread(target=solve_calibration_instance, args=(calibration_config, calibration_solve_times,))\n",
    "            threads.append(x)\n",
    "            x.start()\n",
    "    \n",
    "    done = True\n",
    "    while done:\n",
    "        instance = next(instances)\n",
    "        instance_before_reset = instance.copy_orig()\n",
    "        agent.before_reset(instance_before_reset)\n",
    "        env.seed(seed)\n",
    "        obs, action_set, reward, done, info = env.reset(instance)\n",
    "        \n",
    "    start_t = time.time()\n",
    "    while not done:\n",
    "        action, _ = agent.action_select(action_set, env.model, done)\n",
    "        obs, action_set, reward, done, info = env.step(action)\n",
    "    solve_time = time.time() - start_t\n",
    "    eval_solve_times.append(solve_time)\n",
    "\n",
    "    if episode_counter % calibration_freq == 0:\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "            \n",
    "    # calc calibrated time\n",
    "    calibrated_solves = solve_time / np.mean(calibration_solve_times)\n",
    "    calibrated_solve_time = calibrated_solves * calibration_config['mean_solving_time']\n",
    "    print(f'Solved instance with {info[\"num_nodes\"]} nodes in {solve_time:.3f} s --> calibrated_solves: {calibrated_solves} | calibrated_solve_time: {calibrated_solve_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calibration_solve_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlgnn",
   "language": "python",
   "name": "rlgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
